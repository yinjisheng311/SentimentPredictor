{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads dev.in as a list, and separates each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 24242, 'I-positive': 607, 'B-positive': 1208, 'I-negative': 133, 'B-negative': 382, 'I-neutral': 23, 'B-neutral': 65}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "    \n",
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "def split_into_sentences(dev_in_list):\n",
    "    sentences = []\n",
    "    each_sentence = []\n",
    "    for word in dev_in_list:\n",
    "        if word == \"\":\n",
    "            sentences.append(each_sentence)\n",
    "            each_sentence = []\n",
    "        else:\n",
    "            each_sentence.append(word)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "modified_train_list = load_modified_train_file()   \n",
    "dev_in_list = load_files()\n",
    "sentences = split_into_sentences(dev_in_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giant Emission and Giant Transition Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9401709401709402\n"
     ]
    }
   ],
   "source": [
    "def count_word_tag_pair_dict():\n",
    "    word_tag_pair_dict= {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair_dict.get(word_tag_pair) == None:\n",
    "            word_tag_pair_dict[word_tag_pair] = 1\n",
    "        else:\n",
    "            word_tag_pair_dict[word_tag_pair] += 1\n",
    "    return word_tag_pair_dict\n",
    "\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "\n",
    "def store_estimate_emission_fix():\n",
    "    giantEmissionDict = {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair != \"\":\n",
    "            word_tag_pair_list = word_tag_pair.split(\" \")\n",
    "            countTop = wordTagPairDict[word_tag_pair]\n",
    "            countBottom = annotationDict[word_tag_pair_list[1]]\n",
    "            emission = countTop/countBottom\n",
    "            if giantEmissionDict.get(word_tag_pair) == None:\n",
    "                giantEmissionDict[word_tag_pair] = countTop/countBottom\n",
    "    return giantEmissionDict\n",
    "\n",
    "def store_estimate_transition():\n",
    "    giantTransitionDict = {}\n",
    "    finalGiantTransitionDict = {}\n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if giantTransitionDict.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "    for eachTransition in giantTransitionDict:\n",
    "        eachTransitionList = eachTransition.split(\" \")\n",
    "        startState = eachTransitionList[0]\n",
    "        countTop = giantTransitionDict[eachTransition]\n",
    "        countBottom = totalStateNumber[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        finalGiantTransitionDict[eachTransition] = transitionParam\n",
    "        \n",
    "    return finalGiantTransitionDict\n",
    "\n",
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    totalStateNumber = {}\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    \n",
    "    for each_tweet in giant_each_tweet:\n",
    "        for tag in each_tweet:\n",
    "            if totalStateNumber.get(tag) == None:\n",
    "                totalStateNumber[tag] = 1\n",
    "            else:\n",
    "                totalStateNumber[tag] += 1\n",
    "\n",
    "    return giant_each_tweet, countStart, totalStateNumber\n",
    "\n",
    "modifiedWordDict = get_word_dict()\n",
    "wordTagPairDict = count_word_tag_pair_dict()\n",
    "giantEmissionDict = store_estimate_emission_fix()\n",
    "giantTaggedEachTweet, countStart, totalStateNumber = separate_tweets()\n",
    "giantTransitionDict = store_estimate_transition()\n",
    "print(giantTransitionDict[\"START O\"])\n",
    "# print(giantTransitionDict)\n",
    "# print(len(giantTransitionDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prob(i,u, sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    last_word = sentence[len(sentence)-1]\n",
    "    # base case\n",
    "    if i == 1:\n",
    "        if giantTransitionDict.get(\"START\" + \" \" + u) != None:\n",
    "            a = giantTransitionDict[\"START\" + \" \" + u]#transition from start to u\n",
    "            return a\n",
    "        else:\n",
    "#             print(u)\n",
    "            return 0\n",
    "    # recursive case\n",
    "    else:\n",
    "        word_at_u = sentence[i-1]\n",
    "#         print(word_at_u)\n",
    "        if word_at_u in modifiedWordDict:\n",
    "            word_at_u = word_at_u\n",
    "        else:\n",
    "            word_at_u = \"#UNK#\"\n",
    "        forward_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if giantTransitionDict.get(v + \" \"+ u) != None and giantEmissionDict.get(word_at_u+\" \"+v ) != None:\n",
    "                a = giantTransitionDict[v +\" \"+ u]#transition from v to u #read from dict\n",
    "                b = giantEmissionDict[word_at_u + \" \"+ v]#emission from v to xi #read from dict\n",
    "                forward_prob_from_v = forward_prob(i-1, v, sentence)*a*b\n",
    "                forward_prob_list.append(forward_prob_from_v)\n",
    "        return sum(forward_prob_list)\n",
    "    \n",
    "def back_prob(i,u, sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    last_word = sentence[len(sentence)-1]\n",
    "    n = len(sentence)\n",
    "    # base case\n",
    "    if i == n:\n",
    "        if giantTransitionDict.get(u + \" \" + \"STOP\") != None and giantEmissionDict.get(last_word + \" \" + u) != None:\n",
    "            a = giantTransitionDict[u + \" \" + \"STOP\"]#transition from u to stop\n",
    "            b = giantEmissionDict[last_word + \" \" + u]#emission from u to xn\n",
    "            return a*b\n",
    "        else:\n",
    "            return 0\n",
    "    # recursive case\n",
    "    else:\n",
    "        word_at_v = sentence[i]\n",
    "        if word_at_v in modifiedWordDict:\n",
    "            word_at_v = word_at_v\n",
    "        else:\n",
    "            word_at_v = \"#UNK#\"\n",
    "        back_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if i == 1:\n",
    "                v = \"START\"\n",
    "            if giantTransitionDict.get(u + \" \"+ v) != None and giantEmissionDict.get(word_at_v + \" \" + u) != None:\n",
    "                a = giantTransitionDict[u + \" \" + v]#transition from u to v\n",
    "                b = giantEmissionDict[word_at_v + \" \" + u]#emission from u to xi\n",
    "                back_prob_from_v = back_prob(i + 1, v, sentence) * a * b\n",
    "                back_prob_list.append(back_prob_from_v)\n",
    "#                 print(back_prob_list)\n",
    "\n",
    "        return sum(back_prob_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_path(best_path, sentence):\n",
    "#     print(best_path)\n",
    "#     print(sentence)\n",
    "#     print(len(best_path))\n",
    "#     print(len(sentence))\n",
    "    result = \"\"\n",
    "    for i in range(len(sentence)):\n",
    "        if (sentence[i] == ''):\n",
    "            result += \" \\n\"\n",
    "        else:\n",
    "            result += sentence[i] + \" \" + best_path[i] + \"\\n\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Decoding Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0, 'I-neutral': 0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0, 'I-neutral': 0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0.0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0.0, 'I-neutral': 0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0, 'I-neutral': 0}\n",
      "O\n",
      "{'O': 0.0}\n",
      "B-negative\n",
      "{'O': 0.0, 'B-negative': 0.0}\n",
      "B-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0}\n",
      "B-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0}\n",
      "I-negative\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0}\n",
      "I-positive\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0}\n",
      "I-neutral\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0, 'I-positive': 0, 'I-neutral': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_marginal(sentence):\n",
    "    sentence.append(\"\")\n",
    "    #sentence is a list containing the words\n",
    "    # this is only for one sentence\n",
    "    opti_path = []\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    for i in range(len(sentence)-1): #minus 1, so you dont consider \"\"\n",
    "        opti_y_dict = {}\n",
    "        for tag in all_tags:\n",
    "            print(tag)\n",
    "            f = forward_prob(i,tag, sentence)\n",
    "            b = back_prob(i,tag, sentence)\n",
    "            opti_y_at_i = f*b\n",
    "            opti_y_dict[tag] = opti_y_at_i\n",
    "            print(opti_y_dict)\n",
    "        max_i_path = max(opti_y_dict, key=opti_y_dict.get)\n",
    "\n",
    "        opti_path.append(max_i_path)\n",
    "    return opti_path\n",
    "\n",
    "shortSentence = ['The', 'tuna', 'and', '#UNK#', 'potatoes', 'are', 'excellent', '.']\n",
    "max_marginal(shortSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Decoding By Zanette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_marginal(td,transition,emission,alpha_base):\n",
    "    print(\"Doing max marginal...\")\n",
    "    sentences = split_sentence(td)\n",
    "#     sentence = sentences[0] #test on one sentence first \n",
    "#     print(sentence)\n",
    "    MASSIVE_YSTAR=[]\n",
    "    for sentence in sentences:\n",
    "        betaBase = beta_base(transition,emission,sentence) #get the beta base \n",
    "        forward = {} \n",
    "        forward[1] = alpha_base #this should be constant\n",
    "        YSTAR = [] \n",
    "        #now do forward \n",
    "        for j in range(1,len(sentence)-1):\n",
    "    #         print(sentence[j])\n",
    "            temp_alphas = {}\n",
    "            for u in TAGS:\n",
    "                alpha_j_1_v = 0.0 #value of alpha u (j+1) \n",
    "                for v in TAGS:\n",
    "                    a = 0.0 \n",
    "                    b = 0.0 \n",
    "                    if (v,u) in transition:\n",
    "                        a = transition[(v,u)]\n",
    "                    if (sentence[j],v) in emission:\n",
    "                        b = emission[(sentence[j],v)]\n",
    "                    alpha_j_1_v += float(forward[j][v] * a * b )\n",
    "                temp_alphas[u] = alpha_j_1_v\n",
    "            forward[j+1]= temp_alphas\n",
    "\n",
    "        #now do backward\n",
    "        backwards = {}\n",
    "        backwards[len(sentence)-1] = betaBase # inserting beta u n\n",
    "        for j in range(len(sentence)-2,0,-1): #j = n-1 ,...,1 \n",
    "            temp_beta={}\n",
    "            for u in TAGS: \n",
    "                beta_u_j = 0.0 \n",
    "                for v in TAGS:\n",
    "                    a = 0.0 \n",
    "                    b = 0.0 \n",
    "                    if (u,v) in transition:\n",
    "                        a = transition[(u,v)]\n",
    "                    if (sentence[j],u) in emission:\n",
    "                        b = emission[(sentence[j],u)]\n",
    "                    beta_u_j += float(backwards[j+1][v]*a*b)\n",
    "                temp_beta[u] = beta_u_j\n",
    "            backwards[j] = temp_beta\n",
    "\n",
    "        #find the tags\n",
    "        YSTAR.append(\"START\")\n",
    "        for j in range(1,len(sentence)-1):\n",
    "            temp = {}\n",
    "            for u in TAGS:\n",
    "                temp[u] = forward[j][u] * backwards[j][u]\n",
    "            YSTAR.append(max(temp,key=temp.get))\n",
    "        YSTAR.append(\"STOP\")\n",
    "        MASSIVE_YSTAR.append(YSTAR)\n",
    "    MASSIVE_YSTAR = process_viterbi_results(MASSIVE_YSTAR,sentences)\n",
    "    return MASSIVE_YSTAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Decoding Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'O': 0.9401709401709402, 'B-negative': 0.010683760683760684, 'B-positive': 0.0438034188034188, 'B-neutral': 0.005341880341880342, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}, 2: {'O': 0.00016041691565557236, 'B-negative': 1.1555435393460846e-06, 'B-positive': 3.604271538237371e-06, 'B-neutral': 1.7605233978956968e-07, 'I-negative': 1.1745075025777505e-05, 'I-positive': 2.1612581094621358e-05, 'I-neutral': 0.0}, 3: {'O': 4.8999089587278935e-06, 'B-negative': 7.541558282861202e-08, 'B-positive': 2.3522976804713884e-07, 'B-neutral': 1.1489908741201277e-08, 'I-negative': 1.4076295468736675e-07, 'I-positive': 2.3181748487835117e-07, 'I-neutral': 0.0}, 4: {'O': 6.113739625514341e-07, 'B-negative': 8.503587755151126e-09, 'B-positive': 2.6523655989751155e-08, 'B-neutral': 1.2955604613111133e-09, 'I-negative': 1.724144909916714e-08, 'I-positive': 4.979362996071245e-08, 'I-neutral': 3.8888921893296635e-10}, 5: {'O': 1.3276712628426212e-10, 'B-negative': 3.7571318276561267e-13, 'B-positive': 1.1718920880722433e-12, 'B-neutral': 5.724162064296038e-14, 'I-negative': 0.0, 'I-positive': 7.330445823559772e-11, 'I-neutral': 0.0}, 6: {'O': 6.171125407834623e-13, 'B-negative': 1.0688366704544926e-14, 'B-positive': 3.3338229665699684e-14, 'B-neutral': 1.628421520083022e-15, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}, 7: {'O': 5.91194870949796e-16, 'B-negative': 1.0239473608063924e-17, 'B-positive': 3.1938081115457e-17, 'B-neutral': 1.560030605106692e-18, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}}\n",
      "{7: {'O': 0.004791750040835355, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}, 6: {'O': 4.590504745566912e-06, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}, 5: {'O': 2.1337044239023627e-08, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}, 4: {'O': 7.570712934530349e-13, 'B-negative': 0.0, 'B-positive': 1.2165324990452487e-11, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 4.1116413424128645e-11, 'I-neutral': 0.0}, 3: {'O': 1.417104733276967e-13, 'B-negative': 1.0850824628925195e-13, 'B-positive': 3.098490129003317e-12, 'B-neutral': 1.0052473269281717e-13, 'I-negative': 1.164132465482647e-13, 'I-positive': 5.969815479649591e-12, 'I-neutral': 9.302388293846363e-14}, 2: {'O': 8.448231576168417e-15, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 3.9587856709308075e-15, 'I-positive': 6.621710539064158e-14, 'I-neutral': 5.2409735021638816e-15}, 1: {'O': 5.995126161910482e-19, 'B-negative': 3.894787571110268e-17, 'B-positive': 4.230500664993187e-17, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 1.0506065827850398e-16, 'I-neutral': 0.0}}\n",
      "['B-positive', 'I-positive', 'I-positive', 'I-positive', 'O', 'O', 'O']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B-positive', 'I-positive', 'I-positive', 'I-positive', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_marginal(sentence):\n",
    "#     sentence.append()\n",
    "    #sentence is a list containing the words\n",
    "    # this is only for one sentence\n",
    "    opti_path = []\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    # forward part\n",
    "    forward = {}\n",
    "    alpha_base = {}\n",
    "    for u in all_tags:\n",
    "        if giantTransitionDict.get(\"START\" + \" \" + u) != None:\n",
    "            alpha_base[u] = giantTransitionDict[\"START\" + \" \" + u]\n",
    "        else:\n",
    "            alpha_base[u] = 0.0\n",
    "    forward[1] = alpha_base\n",
    "    for i in range(1,len(sentence)-1):\n",
    "        if sentence[i] in modifiedWordDict:\n",
    "            sentence[i] = sentence[i]\n",
    "        else:\n",
    "            sentence[i] = \"#UNK#\"\n",
    "            \n",
    "        tempAlpha = {}\n",
    "        for u in all_tags:\n",
    "            alpha = 0.0\n",
    "            for v in all_tags:\n",
    "                a = 0.0\n",
    "                b = 0.0\n",
    "                if giantTransitionDict.get(v + \" \" + u) != None:\n",
    "                    a = giantTransitionDict[v + \" \" + u]\n",
    "                if giantEmissionDict.get(sentence[i] + \" \" + v) != None:\n",
    "                    b = giantEmissionDict[sentence[i] + \" \" + v]\n",
    "                alpha += float(forward[i][v] * a * b)\n",
    "            tempAlpha[u] = alpha\n",
    "        forward[i + 1] = tempAlpha\n",
    "    \n",
    "    \n",
    "    # backward part\n",
    "    lastWord = sentence[len(sentence)-1] #last word \n",
    "    if lastWord in modifiedWordDict:\n",
    "        lastWord = lastWord\n",
    "    else:\n",
    "        lastWord = \"#UNK#\"\n",
    "    backwards = {} \n",
    "    beta_base = {}\n",
    "    for u in all_tags:\n",
    "        transition_v = 0.0 \n",
    "        emission_v = 0.0 \n",
    "        if giantTransitionDict.get(u + \" \" + \"STOP\") != None:\n",
    "            transition_v = giantTransitionDict[u + \" \" + \"STOP\"]\n",
    "        if giantEmissionDict.get(lastWord + \" \" + u) != None:\n",
    "            emission_v = giantEmissionDict[lastWord + \" \" + u]\n",
    "        beta_base[u] = float(transition_v * emission_v)\n",
    "    backwards[len(sentence)-1] = beta_base\n",
    "    for i in range(len(sentence)-2, 0, -1): #n-1, n-2 .... 1\n",
    "        if sentence[i] in modifiedWordDict:\n",
    "            sentence[i] = sentence[i]\n",
    "        else:\n",
    "            sentence[i] = \"#UNK#\"\n",
    "            \n",
    "        tempBeta = {}\n",
    "        for u in all_tags:\n",
    "            beta = 0.0\n",
    "            for v in all_tags:\n",
    "                a = 0.0\n",
    "                b = 0.0\n",
    "#                 print(\"POTATOES\")\n",
    "#                 print(giantEmissionDict[\"potatoes I-positive\"])\n",
    "#                 print(giantTransitionDict[\"I-positive I-positive\"])\n",
    "                if giantTransitionDict.get(u + \" \" + v) != None:\n",
    "                    a = giantTransitionDict[u + \" \" + v]\n",
    "                if giantEmissionDict.get(sentence[i] + \" \" + u) != None:\n",
    "                    b = giantEmissionDict[sentence[i] + \" \" + u]\n",
    "#                 print(backwards[i+1])\n",
    "                beta += float(backwards[i+1][v]*a*b)                \n",
    "            tempBeta[u] = beta\n",
    "        backwards[i] = tempBeta\n",
    "    print(forward)\n",
    "    print(backwards)\n",
    "    for j in range(1,len(sentence)):\n",
    "        temp = {}\n",
    "        for u in all_tags:\n",
    "            temp[u] = forward[j][u] * backwards[j][u]\n",
    "        opti_path.append(max(temp,key=temp.get))\n",
    "    print(opti_path)\n",
    "    return opti_path\n",
    "\n",
    "max_marginal([\"The\", \"tuna\", \"and\", \"wasabe\", \"potatoes\", \"are\", \"excellent\", \".\"])\n",
    "# for sentence in sentences:\n",
    "#     max_marginal(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
