{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "### Implementation of a second order HMM and decoding with Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 24242, 'I-positive': 607, 'B-positive': 1208, 'I-negative': 133, 'B-negative': 382, 'I-neutral': 23, 'B-neutral': 65}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_word_tag_pair_dict():\n",
    "    word_tag_pair_dict= {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair_dict.get(word_tag_pair) == None:\n",
    "            word_tag_pair_dict[word_tag_pair] = 1\n",
    "        else:\n",
    "            word_tag_pair_dict[word_tag_pair] += 1\n",
    "    return word_tag_pair_dict\n",
    "\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "\n",
    "def store_estimate_emission_fix():\n",
    "    giantEmissionDict = {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair != \"\":\n",
    "            word_tag_pair_list = word_tag_pair.split(\" \")\n",
    "            countTop = wordTagPairDict[word_tag_pair]\n",
    "            countBottom = annotationDict[word_tag_pair_list[len(word_tag_pair_list)-1]]\n",
    "            emission = countTop/countBottom\n",
    "            if giantEmissionDict.get(word_tag_pair) == None:\n",
    "                giantEmissionDict[word_tag_pair] = countTop/countBottom\n",
    "    return giantEmissionDict\n",
    "\n",
    "def store_estimate_transition():\n",
    "    giantTransitionDict = {}\n",
    "    finalGiantTransitionDict = {}\n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if giantTransitionDict.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "    for eachTransition in giantTransitionDict:\n",
    "        eachTransitionList = eachTransition.split(\" \")\n",
    "        startState = eachTransitionList[0]\n",
    "        countTop = giantTransitionDict[eachTransition]\n",
    "        countBottom = totalStateNumber[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        finalGiantTransitionDict[eachTransition] = transitionParam\n",
    "        \n",
    "    return finalGiantTransitionDict\n",
    "\n",
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    totalStateNumber = {}\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[len(each_word)-1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    \n",
    "    for each_tweet in giant_each_tweet:\n",
    "        for tag in each_tweet:\n",
    "            if totalStateNumber.get(tag) == None:\n",
    "                totalStateNumber[tag] = 1\n",
    "            else:\n",
    "                totalStateNumber[tag] += 1\n",
    "\n",
    "    return giant_each_tweet, countStart, totalStateNumber\n",
    "\n",
    "modifiedWordDict = get_word_dict()\n",
    "wordTagPairDict = count_word_tag_pair_dict()\n",
    "giantEmissionDict = store_estimate_emission_fix()\n",
    "giantTaggedEachTweet, countStart, totalStateNumber = separate_tweets()\n",
    "giantTransitionDict = store_estimate_transition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'START O O': 0.7755681818181818, 'O O O': 0.8720913496137792, 'O O STOP': 0.07618864846711126, 'START B-neutral O': 0.9, 'B-neutral O O': 0.9019607843137255, 'START O B-positive': 0.1653409090909091, 'O B-positive O': 0.6900532859680284, 'B-positive O O': 0.7884615384615384, 'O O B-negative': 0.013625677685553903, 'O B-negative O': 0.7811634349030471, 'B-negative O STOP': 0.12416107382550336, 'O O B-positive': 0.03660701434534376, 'B-positive O STOP': 0.15264423076923078, 'START O B-negative': 0.040340909090909094, 'B-negative O O': 0.8624161073825504, 'O B-negative I-negative': 0.21052631578947367, 'B-negative I-negative I-negative': 0.3875, 'I-negative I-negative O': 0.5849056603773585, 'I-negative O O': 0.8, 'O O B-neutral': 0.0014873098882118697, 'O B-neutral O': 0.7636363636363637, 'O B-positive I-positive': 0.29573712255772644, 'B-positive I-positive O': 0.6083333333333333, 'I-positive O O': 0.7549295774647887, 'START O B-neutral': 0.013068181818181817, 'B-positive I-positive I-positive': 0.38055555555555554, 'I-positive I-positive O': 0.5506072874493927, 'START B-positive I-positive': 0.32926829268292684, 'B-negative O B-negative': 0.013422818791946308, 'START O STOP': 0.005681818181818182, 'START B-positive O': 0.6707317073170732, 'I-positive I-positive I-positive': 0.44534412955465585, 'I-positive O STOP': 0.18028169014084508, 'I-negative O STOP': 0.175, 'O B-neutral I-neutral': 0.21818181818181817, 'B-neutral I-neutral I-neutral': 0.46153846153846156, 'I-neutral I-neutral O': 0.6, 'I-neutral O O': 0.7692307692307693, 'B-positive O B-positive': 0.05889423076923077, 'I-positive O B-positive': 0.0647887323943662, 'O B-negative STOP': 0.008310249307479225, 'B-negative I-negative O': 0.6125, 'I-neutral I-neutral I-neutral': 0.4, 'I-neutral O STOP': 0.15384615384615385, 'START B-negative I-negative': 0.2, 'B-positive I-positive STOP': 0.011111111111111112, 'I-negative I-negative I-negative': 0.41509433962264153, 'START B-negative O': 0.8, 'B-neutral O STOP': 0.09803921568627451, 'O B-positive STOP': 0.014209591474245116, 'I-positive I-positive STOP': 0.004048582995951417, 'O B-neutral STOP': 0.01818181818181818, 'B-neutral I-neutral O': 0.5384615384615384, 'START B-neutral I-neutral': 0.1, 'I-neutral O B-neutral': 0.07692307692307693, 'I-negative O B-negative': 0.025}\n"
     ]
    }
   ],
   "source": [
    "def store_second_order_transition():\n",
    "    transitionCount = {}\n",
    "    startStateCount = {}\n",
    "    giantSecondTransitionDict = {}        \n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if startStateCount.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                startStateCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                startStateCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "                \n",
    "        for i in range(len(taggedEachTweet) - 2):\n",
    "            if transitionCount.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1] + \" \" + taggedEachTweet[i+2]) == None:\n",
    "                transitionCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]+ \" \"+ taggedEachTweet[i+2]] = 1\n",
    "            else:\n",
    "                transitionCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]+ \" \"+ taggedEachTweet[i+2]] += 1\n",
    "    for eachTransition in transitionCount:\n",
    "        eachTransitionList = eachTransition.split(\" \") #START O O\n",
    "        startState = eachTransitionList[0] + \" \" + eachTransitionList[1] # START O\n",
    "        countTop = transitionCount[eachTransition]\n",
    "        countBottom = startStateCount[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        giantSecondTransitionDict[eachTransition] = transitionParam\n",
    "\n",
    "    return giantSecondTransitionDict\n",
    "\n",
    "giantSecondTransitionDict = store_second_order_transition()\n",
    "print(giantSecondTransitionDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'O': 0.10952242946302841, 'B-negative': 0.0019577571933592874, 'B-positive': 0.010624504726325918, 'B-neutral': 0.0009040105193951349}, {'START O': 0.00024221306515862052, 'START B-negative': 0.0001000958565025801, 'START B-positive': 0.0012160526263888527, 'START B-neutral': 1.9652402595546413e-05}, {'O B-negative': 2.5578783356529717e-08, 'O B-positive': 9.94562791068425e-08}, {'B-positive STOP': 1.413233095656732e-09}]\n",
      "['STOP', 'B-positive', 'O']\n",
      "{'O': 0.10952242946302841, 'B-negative': 0.0019577571933592874, 'B-positive': 0.010624504726325918, 'B-neutral': 0.0009040105193951349}\n",
      "[{'B-positive': 0.00014504443312390332, 'B-neutral': 8.21827744904668e-05}, {'START B-positive': 1.701560172955939e-06}, {'B-positive O': 7.4384900942866305e-09}, {'O O': 2.2814373537614629e-10}, {'O O': 1.3952466906739993e-13}, {'O O': 2.5096579686371738e-17}, {'O O': 1.375919532845953e-18}, {'O STOP': 1.0482944960703226e-19}]\n",
      "['STOP', 'O', 'O', 'O', 'O', 'O', 'B-positive']\n",
      "{'B-positive': 0.00014504443312390332, 'B-neutral': 8.21827744904668e-05}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7263723bef95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lobster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'was'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'good'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nothing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spectacular'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mbacktrack_second_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mbacktrack_second_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-7263723bef95>\u001b[0m in \u001b[0;36mbacktrack_second_order\u001b[0;34m(piList, sentence)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mscoreOfTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentLayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgiantTransitionDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtargetedTag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mscoreDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreOfTag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mbestScoreTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoreDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoreDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestScoreTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "def backtrack_second_order(piList, sentence):\n",
    "    path = []\n",
    "    print(piList)\n",
    "    singleStringToBeWritten = \"\"\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    if len(piList) == len(sentence):\n",
    "        for i in range(len(piList)):\n",
    "            if i == 0:\n",
    "                lastLayer = piList[len(piList)- (i+1)]\n",
    "                maxPiTag = max(lastLayer, key=lastLayer.get)\n",
    "                maxPiTagList = maxPiTag.split(\" \")\n",
    "                path.append(maxPiTagList[len(maxPiTagList)-1])\n",
    "            elif i == 1:\n",
    "                path.append(maxPiTagList[0])\n",
    "\n",
    "            elif i == len(piList)-1:\n",
    "                print(path)\n",
    "                currentLayer = piList[len(piList) - (i+1)] #1st layer\n",
    "                print(currentLayer)\n",
    "                targetedTag = path[i-1]\n",
    "                scoreDict = {}\n",
    "                for tag in currentLayer:\n",
    "                    if giantTransitionDict.get(tag + \" \" + targetedTag) != None:\n",
    "                        scoreOfTag = currentLayer[tag]*giantTransitionDict[tag + \" \" + targetedTag]\n",
    "                        scoreDict[tag] = scoreOfTag\n",
    "                bestScoreTag = max(scoreDict, key=scoreDict.get)\n",
    "                path.append(bestScoreTag)\n",
    "    \n",
    "            else:\n",
    "                currentLayer = piList[len(piList) - (i+1)] #2nd last layer onwards\n",
    "                targetedTag = path[i-1]\n",
    "                scoreDict = {}\n",
    "                for tags in currentLayer:\n",
    "                    if giantSecondTransitionDict.get(tags + \" \" + targetedTag) != None:\n",
    "                        scoreOfTag = currentLayer[tags]*giantSecondTransitionDict[tags + \" \" + targetedTag]\n",
    "                        scoreDict[tags] = scoreOfTag\n",
    "                bestScoreTag = max(scoreDict, key=scoreDict.get)\n",
    "                bestScoreTagList = bestScoreTag.split(\" \")\n",
    "                path.append(bestScoreTagList[len(bestScoreTagList)-1])\n",
    "                if bestScoreTagList[0] == \"START\":\n",
    "\n",
    "    path.remove(\"STOP\")\n",
    "    for j in range(len(sentence)):\n",
    "        if sentence[j] == \"\":\n",
    "            singleStringToBeWritten += \"\\n\"\n",
    "        else:\n",
    "            singleStringToBeWritten += sentence[j] + \" \" + path[len(path)-(j+1)] + \"\\n\"\n",
    "    return singleStringToBeWritten\n",
    "piList = [{'O': 0.10952242946302841, 'B-negative': 0.0019577571933592874, 'B-positive': 0.010624504726325918, 'B-neutral': 0.0009040105193951349}, {'START O': 0.00024221306515862052, 'START B-negative': 0.0001000958565025801, 'START B-positive': 0.0012160526263888527, 'START B-neutral': 1.9652402595546413e-05}, {'O B-negative': 2.5578783356529717e-08, 'O B-positive': 9.94562791068425e-08}, {'B-positive STOP': 1.413233095656732e-09}]\n",
    "sentence = ['AVOID', 'THAT', 'PLACE', '']\n",
    "piList2 = [{'B-positive': 0.00014504443312390332, 'B-neutral': 8.21827744904668e-05}, {'START B-positive': 1.701560172955939e-06}, {'B-positive O': 7.4384900942866305e-09}, {'O O': 2.2814373537614629e-10}, {'O O': 1.3952466906739993e-13}, {'O O': 2.5096579686371738e-17}, {'O O': 1.375919532845953e-18}, {'O STOP': 1.0482944960703226e-19}]\n",
    "sentence2 = ['lobster', 'was', 'good', ',', 'nothing', 'spectacular', '.', '']\n",
    "backtrack_second_order(piList, sentence)\n",
    "backtrack_second_order(piList2, sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "    \n",
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "def split_into_sentences(dev_in_list):\n",
    "    sentences = []\n",
    "    each_sentence = []\n",
    "    for word in dev_in_list:\n",
    "        if word == \"\":\n",
    "            sentences.append(each_sentence)\n",
    "            each_sentence = []\n",
    "        else:\n",
    "            each_sentence.append(word)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "modified_train_list = load_modified_train_file()   \n",
    "dev_in_list = load_files()\n",
    "sentences = split_into_sentences(dev_in_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'B-positive': 0.00014504443312390332, 'B-neutral': 8.21827744904668e-05}, {'START B-positive': 1.701560172955939e-06}, {'B-positive O': 7.4384900942866305e-09}, {'O O': 2.2814373537614629e-10}, {'O O': 1.3952466906739993e-13}, {'O O': 2.5096579686371738e-17}, {'O O': 1.375919532845953e-18}, {'O STOP': 1.0482944960703226e-19}]\n",
      "['lobster', 'was', 'good', ',', 'nothing', 'spectacular', '.', '']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d825f6a6c3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# f.write(giantStringToBeWritten)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# second_order_viterbi([\"The\", \"tuna\", \"and\", \"wasabe\", \"potatoes\", \"are\", \"excellent\", \".\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0msecond_order_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lobster\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"was\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"good\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nothing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"spectacular\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-d825f6a6c3c6>\u001b[0m in \u001b[0;36msecond_order_viterbi\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mpiLayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaxPiTag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxPiScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mpiList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0msingleStringToBeWritten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktrack_second_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;31m#                 print(singleStringToBeWritten)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msingleStringToBeWritten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-41f2166b243e>\u001b[0m in \u001b[0;36mbacktrack_second_order\u001b[0;34m(piList, sentence)\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mscoreOfTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentLayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgiantTransitionDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtargetedTag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mscoreDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreOfTag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mbestScoreTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoreDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoreDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestScoreTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "def second_order_viterbi(sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    sentence.append(\"\") #so we can detect the end\n",
    "    piList = []\n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        if word in modifiedWordDict:\n",
    "            word = word\n",
    "        else:\n",
    "            word = \"#UNK#\"\n",
    "            \n",
    "        piLayer = {}\n",
    "        if i == 0:\n",
    "            for tag in all_tags:\n",
    "                if giantTransitionDict.get(\"START\" + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None:\n",
    "                    pi = giantTransitionDict[\"START\" + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                    piLayer[tag] = pi\n",
    "            piList.append(piLayer)\n",
    "        \n",
    "        elif i == 1:\n",
    "            previousLayer = piList[len(piList)-1]\n",
    "            for tag in all_tags:\n",
    "                tempLayer = {}\n",
    "                for previous_tag in previousLayer:\n",
    "                    if giantSecondTransitionDict.get(\"START\" + \" \" + previous_tag + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None:\n",
    "                        pi = previousLayer[previous_tag]*giantSecondTransitionDict[\"START\" + \" \" + previous_tag + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                        tempLayer[\"START\" + \" \" + previous_tag] = pi\n",
    "                if len(tempLayer) != 0:\n",
    "                    maxPiTag = max(tempLayer, key=tempLayer.get) \n",
    "                    maxPiScore = max(tempLayer.values())\n",
    "                    piLayer[maxPiTag] = maxPiScore\n",
    "            piList.append(piLayer)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            previousLayer = piList[len(piList)-1]\n",
    "            if word == \"\":\n",
    "#                 print(piList)\n",
    "                tempLayer = {}\n",
    "                for previous_tags in previousLayer:\n",
    "                    previous_tags_list = previous_tags.split(\" \")\n",
    "                    if giantSecondTransitionDict.get(previous_tags + \" \" + \"STOP\") != None:\n",
    "                        pi = previousLayer[previous_tags]*giantSecondTransitionDict[previous_tags + \" \" + \"STOP\"]\n",
    "                        tagOneLayerBefore = previous_tags_list[len(previous_tags_list)-1]\n",
    "                        tempLayer[tagOneLayerBefore+ \" \" + \"STOP\"] = pi\n",
    "                if len(tempLayer) != 0:\n",
    "                    maxPiTag = max(tempLayer, key=tempLayer.get) \n",
    "                    maxPiScore = max(tempLayer.values())\n",
    "                    piLayer[maxPiTag] = maxPiScore\n",
    "                piList.append(piLayer)\n",
    "                singleStringToBeWritten = backtrack_second_order(piList, sentence)\n",
    "#                 print(singleStringToBeWritten)\n",
    "                return singleStringToBeWritten\n",
    "            else:\n",
    "                for tag in all_tags:\n",
    "                    tempLayer = {}\n",
    "                    for previous_tags in previousLayer:\n",
    "                        previous_tags_list = previous_tags.split(\" \")\n",
    "                        if giantSecondTransitionDict.get(previous_tags + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None:\n",
    "                            pi = previousLayer[previous_tags]*giantSecondTransitionDict[previous_tags + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                            tagOneLayerBefore = previous_tags_list[len(previous_tags_list)-1]\n",
    "                            tempLayer[tagOneLayerBefore+ \" \" + tag] = pi\n",
    "                    if len(tempLayer) != 0:\n",
    "                        maxPiTag = max(tempLayer, key=tempLayer.get) \n",
    "                        maxPiScore = max(tempLayer.values())\n",
    "                        piLayer[maxPiTag] = maxPiScore\n",
    "                piList.append(piLayer)\n",
    "    \n",
    "                        \n",
    "\n",
    "            \n",
    "giantStringToBeWritten = \"\"    \n",
    "# for sentence in sentences:\n",
    "#     singleStringToBeWritten = second_order_viterbi(sentence)\n",
    "#     print(singleStringToBeWritten)\n",
    "#     giantStringToBeWritten += singleStringToBeWritten\n",
    "# print(giantStringToBeWritten)\n",
    "# f = open(\"dev.p5.out\",\"w+\")\n",
    "# f.write(giantStringToBeWritten)\n",
    "# second_order_viterbi([\"The\", \"tuna\", \"and\", \"wasabe\", \"potatoes\", \"are\", \"excellent\", \".\"])\n",
    "second_order_viterbi([\"lobster\", \"was\", \"good\", \",\", \"nothing\",\"spectacular\",\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
