{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "### Implementation of a second order HMM and decoding with Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 24242, 'I-positive': 607, 'B-positive': 1208, 'I-negative': 133, 'B-negative': 382, 'I-neutral': 23, 'B-neutral': 65}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "    \n",
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "def split_into_sentences(dev_in_list):\n",
    "    sentences = []\n",
    "    each_sentence = []\n",
    "    for word in dev_in_list:\n",
    "        if word == \"\":\n",
    "            sentences.append(each_sentence)\n",
    "            each_sentence = []\n",
    "        else:\n",
    "            each_sentence.append(word)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "modified_train_list = load_modified_train_file()   \n",
    "dev_in_list = load_files()\n",
    "sentences = split_into_sentences(dev_in_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_word_tag_pair_dict():\n",
    "    word_tag_pair_dict= {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair_dict.get(word_tag_pair) == None:\n",
    "            word_tag_pair_dict[word_tag_pair] = 1\n",
    "        else:\n",
    "            word_tag_pair_dict[word_tag_pair] += 1\n",
    "    return word_tag_pair_dict\n",
    "\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "\n",
    "def store_estimate_emission_fix():\n",
    "    giantEmissionDict = {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair != \"\":\n",
    "            word_tag_pair_list = word_tag_pair.split(\" \")\n",
    "            countTop = wordTagPairDict[word_tag_pair]\n",
    "            countBottom = annotationDict[word_tag_pair_list[len(word_tag_pair_list)-1]]\n",
    "            emission = countTop/countBottom\n",
    "            if giantEmissionDict.get(word_tag_pair) == None:\n",
    "                giantEmissionDict[word_tag_pair] = countTop/countBottom\n",
    "    return giantEmissionDict\n",
    "\n",
    "def store_estimate_transition():\n",
    "    giantTransitionDict = {}\n",
    "    finalGiantTransitionDict = {}\n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if giantTransitionDict.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "    for eachTransition in giantTransitionDict:\n",
    "        eachTransitionList = eachTransition.split(\" \")\n",
    "        startState = eachTransitionList[0]\n",
    "        countTop = giantTransitionDict[eachTransition]\n",
    "        countBottom = totalStateNumber[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        finalGiantTransitionDict[eachTransition] = transitionParam\n",
    "        \n",
    "    return finalGiantTransitionDict\n",
    "\n",
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    totalStateNumber = {}\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[len(each_word)-1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    \n",
    "    for each_tweet in giant_each_tweet:\n",
    "        for tag in each_tweet:\n",
    "            if totalStateNumber.get(tag) == None:\n",
    "                totalStateNumber[tag] = 1\n",
    "            else:\n",
    "                totalStateNumber[tag] += 1\n",
    "\n",
    "    return giant_each_tweet, countStart, totalStateNumber\n",
    "\n",
    "modifiedWordDict = get_word_dict()\n",
    "wordTagPairDict = count_word_tag_pair_dict()\n",
    "giantEmissionDict = store_estimate_emission_fix()\n",
    "giantTaggedEachTweet, countStart, totalStateNumber = separate_tweets()\n",
    "giantTransitionDict = store_estimate_transition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'START O O': 0.7755681818181818, 'O O O': 0.8720913496137792, 'O O STOP': 0.07618864846711126, 'START B-neutral O': 0.9, 'B-neutral O O': 0.9019607843137255, 'START O B-positive': 0.1653409090909091, 'O B-positive O': 0.6900532859680284, 'B-positive O O': 0.7884615384615384, 'O O B-negative': 0.013625677685553903, 'O B-negative O': 0.7811634349030471, 'B-negative O STOP': 0.12416107382550336, 'O O B-positive': 0.03660701434534376, 'B-positive O STOP': 0.15264423076923078, 'START O B-negative': 0.040340909090909094, 'B-negative O O': 0.8624161073825504, 'O B-negative I-negative': 0.21052631578947367, 'B-negative I-negative I-negative': 0.3875, 'I-negative I-negative O': 0.5849056603773585, 'I-negative O O': 0.8, 'O O B-neutral': 0.0014873098882118697, 'O B-neutral O': 0.7636363636363637, 'O B-positive I-positive': 0.29573712255772644, 'B-positive I-positive O': 0.6083333333333333, 'I-positive O O': 0.7549295774647887, 'START O B-neutral': 0.013068181818181817, 'B-positive I-positive I-positive': 0.38055555555555554, 'I-positive I-positive O': 0.5506072874493927, 'START B-positive I-positive': 0.32926829268292684, 'B-negative O B-negative': 0.013422818791946308, 'START O STOP': 0.005681818181818182, 'START B-positive O': 0.6707317073170732, 'I-positive I-positive I-positive': 0.44534412955465585, 'I-positive O STOP': 0.18028169014084508, 'I-negative O STOP': 0.175, 'O B-neutral I-neutral': 0.21818181818181817, 'B-neutral I-neutral I-neutral': 0.46153846153846156, 'I-neutral I-neutral O': 0.6, 'I-neutral O O': 0.7692307692307693, 'B-positive O B-positive': 0.05889423076923077, 'I-positive O B-positive': 0.0647887323943662, 'O B-negative STOP': 0.008310249307479225, 'B-negative I-negative O': 0.6125, 'I-neutral I-neutral I-neutral': 0.4, 'I-neutral O STOP': 0.15384615384615385, 'START B-negative I-negative': 0.2, 'B-positive I-positive STOP': 0.011111111111111112, 'I-negative I-negative I-negative': 0.41509433962264153, 'START B-negative O': 0.8, 'B-neutral O STOP': 0.09803921568627451, 'O B-positive STOP': 0.014209591474245116, 'I-positive I-positive STOP': 0.004048582995951417, 'O B-neutral STOP': 0.01818181818181818, 'B-neutral I-neutral O': 0.5384615384615384, 'START B-neutral I-neutral': 0.1, 'I-neutral O B-neutral': 0.07692307692307693, 'I-negative O B-negative': 0.025}\n"
     ]
    }
   ],
   "source": [
    "def store_second_order_transition():\n",
    "    transitionCount = {}\n",
    "    startStateCount = {}\n",
    "    giantSecondTransitionDict = {}        \n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if startStateCount.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                startStateCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                startStateCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "                \n",
    "        for i in range(len(taggedEachTweet) - 2):\n",
    "            if transitionCount.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1] + \" \" + taggedEachTweet[i+2]) == None:\n",
    "                transitionCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]+ \" \"+ taggedEachTweet[i+2]] = 1\n",
    "            else:\n",
    "                transitionCount[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]+ \" \"+ taggedEachTweet[i+2]] += 1\n",
    "    for eachTransition in transitionCount:\n",
    "        eachTransitionList = eachTransition.split(\" \") #START O O\n",
    "        startState = eachTransitionList[0] + \" \" + eachTransitionList[1] # START O\n",
    "        countTop = transitionCount[eachTransition]\n",
    "        countBottom = startStateCount[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        giantSecondTransitionDict[eachTransition] = transitionParam\n",
    "\n",
    "    return giantSecondTransitionDict\n",
    "\n",
    "giantSecondTransitionDict = store_second_order_transition()\n",
    "print(giantSecondTransitionDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'O': 0.10952242946302841, 'B-negative': 0.0019577571933592874, 'B-positive': 0.010624504726325918, 'B-neutral': 0.0009040105193951349}, {'O': 0.009895079731010215, 'B-negative': 0.0008096240992849406, 'B-positive': 0.004392219908614064, 'B-neutral': 0.00024221306515862052, 'I-negative': 0.0001000958565025801, 'I-positive': 0.0012160526263888527, 'I-neutral': 1.9652402595546413e-05}]\n",
      "[{'O': 0.10952242946302841, 'B-negative': 0.0019577571933592874, 'B-positive': 0.010624504726325918, 'B-neutral': 0.0009040105193951349}, {'O': 0.009895079731010215, 'B-negative': 0.0008096240992849406, 'B-positive': 0.004392219908614064, 'B-neutral': 0.00024221306515862052, 'I-negative': 0.0001000958565025801, 'I-positive': 0.0012160526263888527, 'I-neutral': 1.9652402595546413e-05}]\n"
     ]
    }
   ],
   "source": [
    "def second_order_viterbi(sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    sentence.append(\"\") #so we can detect the end\n",
    "    piList = []\n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        if word in modifiedWordDict:\n",
    "            word = word\n",
    "        else:\n",
    "            word = \"#UNK#\"\n",
    "            \n",
    "        piLayer = {}\n",
    "        if i == 0:\n",
    "            for tag in all_tags:\n",
    "                if giantTransitionDict.get(\"START\" + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None:\n",
    "                    pi = giantTransitionDict[\"START\" + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                    piLayer[tag] = pi\n",
    "            piList.append(piLayer)\n",
    "        \n",
    "        elif i == 1:\n",
    "            previousLayer = piList[len(piList)-1]\n",
    "            for tag in all_tags:\n",
    "                tempLayer = {}\n",
    "                for previous_tag in previousLayer:\n",
    "                    if giantSecondTransitionDict.get(\"START\" + \" \" + previous_tag + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None:\n",
    "                        pi = previousLayer[previous_tag]*giantSecondTransitionDict[\"START\" + \" \" + previous_tag + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                        tempLayer[previous_tag] = pi\n",
    "                if len(tempLayer) != 0:\n",
    "                    maxPiTag = max(tempLayer, key=tempLayer.get) \n",
    "                    maxPiScore = max(tempLayer.values())\n",
    "                    piLayer[tag] = maxPiScore\n",
    "            piList.append(piLayer)\n",
    "            \n",
    "        else:\n",
    "            print(piList)\n",
    "            \n",
    "            previousLayer = piList[len(piList)-1]\n",
    "            previousPreviousLayer = piList[len(piList)-2]\n",
    "            for tag in all_tags:\n",
    "                tempLayer2 = {}\n",
    "                for previous_previous_tag in previousPreviousLayer:\n",
    "                    tempLayer = {}\n",
    "                    for previous_tag in previousLayer:\n",
    "                        if giantSecondTransitionDict.get(previous_previous_tag + \" \" + previous_tag + \" \" + tag) != None and giantEmissionDict.get(word + \" \" + tag) != None and giantTransitionDict.get(previous_previous_tag + \" \" + tag):\n",
    "                            pi = previousLayer[previous_tag]*giantSecondTransitionDict[previous_previous_tag+ \" \" + previous_tag + \" \" + tag]*giantEmissionDict[word + \" \" + tag]\n",
    "                            tempLayer[previous_tag] = pi\n",
    "                    \n",
    "\n",
    "                        \n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "# second_order_viterbi([\"The\", \"tuna\", \"and\", \"wasabe\", \"potatoes\", \"are\", \"excellent\", \".\"])\n",
    "second_order_viterbi([\"AVOID\", \"THAT\", \"PLACE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
