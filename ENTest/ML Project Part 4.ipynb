{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 2667, 'I-positive': 750, 'B-positive': 80, 'I-negative': 115, 'B-negative': 107, 'I-neutral': 203, 'B-neutral': 124}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0307461567304087"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open modified sentiment file \n",
    "def load_modified_senti_file():\n",
    "    with open(\"ENdev.final.out\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "modifiedEN_train_list = load_modified_senti_file()\n",
    "\n",
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(modifiedEN_train_list)):\n",
    "    annotated_word = modifiedEN_train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)\n",
    "def separate_sentitweets():\n",
    "    countStart = 1\n",
    "    countBottom = 0\n",
    "    countTop = 0\n",
    "    # counting starts\n",
    "    giantsenti_each_tweet = []\n",
    "    each_tweet = []\n",
    "    for i in range(len(modifiedEN_train_list)):\n",
    "        annotated_word = modifiedEN_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giantsenti_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[1])\n",
    "    for i in range(len(giantsenti_each_tweet)):\n",
    "        giantsenti_each_tweet[i].insert(0, 'START')\n",
    "        giantsenti_each_tweet[i].append('STOP')\n",
    "    return giantsenti_each_tweet, countStart\n",
    "giantsenti_each_tweet, countStart = separate_sentitweets()\n",
    "\n",
    "def estimate_transition(current_tag, previous_tag):\n",
    "#     with open(\"modified_train_final2\", encoding=\"utf-8\") as file:\n",
    "    startDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "    for i in range(len(giantsenti_each_tweet)):\n",
    "        each_tweet = giantsenti_each_tweet[i]\n",
    "        if each_tweet[1] == \"O\":\n",
    "            startDict[\"O\"] += 1\n",
    "        elif each_tweet[1] == \"I-positive\":\n",
    "            startDict[\"I-positive\"] += 1\n",
    "        elif each_tweet[1] == \"B-positive\":\n",
    "            startDict[\"B-positive\"] += 1\n",
    "        elif each_tweet[1] == \"I-negative\":\n",
    "            startDict[\"I-negative\"] += 1\n",
    "        elif each_tweet[1] == \"B-negative\":\n",
    "            startDict[\"B-negative\"] += 1\n",
    "        elif each_tweet[1] == \"I-neutral\":\n",
    "            startDict[\"I-neutral\"] += 1\n",
    "        elif each_tweet[1] == \"B-neutral\":\n",
    "            startDict[\"B-neutral\"] += 1\n",
    "\n",
    "    stopDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "    for i in range(len(giantsenti_each_tweet)):\n",
    "        each_tweet = giantsenti_each_tweet[i]\n",
    "        last_index = len(each_tweet) - 2\n",
    "        if each_tweet[last_index] == \"O\":\n",
    "            stopDict[\"O\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-positive\":\n",
    "            stopDict[\"I-positive\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-positive\":\n",
    "            stopDict[\"B-positive\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-negative\":\n",
    "            stopDict[\"I-negative\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-negative\":\n",
    "            stopDict[\"B-negative\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-neutral\":\n",
    "            stopDict[\"I-neutral\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-neutral\":\n",
    "            stopDict[\"B-neutral\"] += 1\n",
    "\n",
    "    if previous_tag == \"START\":\n",
    "        # current tag is Yn\n",
    "        countTop = startDict[current_tag]\n",
    "#             print(countTop)\n",
    "#             print(countStart)\n",
    "#             print(countTop/countStart)\n",
    "        return countTop/countStart\n",
    "\n",
    "    elif current_tag == \"STOP\":\n",
    "        # previous tag is Yn\n",
    "        countTop = stopDict[previous_tag]\n",
    "        countBottom = annotationDict[previous_tag]\n",
    "        return countTop/countBottom\n",
    "\n",
    "    else:\n",
    "        giantTransitionDict = {}\n",
    "        for i in range(len(giantsenti_each_tweet)):\n",
    "            each_tweet = giantsenti_each_tweet[i]\n",
    "            for j in range(1,len(each_tweet)-1):\n",
    "                if j == len(each_tweet):\n",
    "                    break\n",
    "                if each_tweet[j-1] == previous_tag and each_tweet[j] == \"O\":\n",
    "                    if (previous_tag + \"O\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"O\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"O\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] == \"B-negative\":\n",
    "                    if (previous_tag + \"B-negative\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-negative\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-negative\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] == \"B-positive\":\n",
    "                    if (previous_tag + \"B-positive\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-positive\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-positive\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"B-neutral\":\n",
    "                    if (previous_tag + \"B-neutral\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-neutral\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-neutral\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-positive\":\n",
    "                    if (previous_tag + \"I-positive\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-positive\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-positive\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-negative\":\n",
    "                    if (previous_tag + \"I-negative\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-negative\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-negative\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-neutral\":\n",
    "                    if (previous_tag + \"I-neutral\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-neutral\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-neutral\"] = 1\n",
    "#             print(giantTransitionDict)\n",
    "        if giantTransitionDict.get(previous_tag+current_tag) == None:\n",
    "            return 0\n",
    "        else:\n",
    "            countTop = giantTransitionDict[previous_tag+current_tag]\n",
    "            countBottom = annotationDict[previous_tag]\n",
    "\n",
    "            return countTop/countBottom\n",
    "\n",
    "    return 1\n",
    "\n",
    "estimate_transition(\"O\", \"START\") #current, previous\n",
    "\n",
    "#estimating emission from dev.out\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modifiedEN_train_list)):\n",
    "        annotated_word = modifiedEN_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "modifiedWordDict = get_word_dict()\n",
    "def estimate_emission_fix(word, tag):\n",
    "        countTop = 0\n",
    "        countBottom = annotationDict[tag]\n",
    "        if word in modifiedWordDict:\n",
    "            # do nothing\n",
    "            word = word\n",
    "            \n",
    "        else:\n",
    "            word = \"#UNK#\"\n",
    "            \n",
    "        for i in range(len(modifiedEN_train_list)):\n",
    "            annotated_word = modifiedEN_train_list[i]\n",
    "            each_word = annotated_word.split(\" \")\n",
    "            if (each_word[0] == word and each_word[1] == tag):\n",
    "                countTop += 1\n",
    "#         print('emission')\n",
    "#         print(countTop)\n",
    "        return countTop/countBottom\n",
    "\n",
    "estimate_emission_fix(\"I\", \"O\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'When,O': 0.0007499062617172854, 'START,O': 0.6591760299625468, 'O,O': 0.6212973378327709, 'O,I-positive': 0.07424071991001124, 'I-positive,O': 0.5973333333333334, 'O,I-negative': 0.004124484439445069, 'I-negative,O': 0.5304347826086957, 'I-positive,I-positive': 0.19066666666666668, 'I-positive,B-positive': 0.024, 'B-positive,O': 0.6625, 'O,STOP': 0.09673790776152981, 'The,B-neutral': 0.3709677419354839, 'START,B-neutral': 0.20224719101123595, 'B-neutral,B-negative': 0.0967741935483871, 'B-negative,I-neutral': 0.12149532710280374, 'I-neutral,I-positive': 0.18226600985221675, 'My,O': 0.003374578177727784, 'I-positive,I-neutral': 0.09066666666666667, 'I-neutral,B-positive': 0.019704433497536946, 'B-positive,I-negative': 0.025, 'Food,B-neutral': 0.016129032258064516, 'B-neutral,I-positive': 0.1693548387096774, 'O,B-negative': 0.006749156355455568, 'B-negative,I-positive': 0.12149532710280374, 'I-positive,B-negative': 0.02266666666666667, 'â€“,O': 0.0029996250468691415, 'I-positive,I-negative': 0.06, 'mouth,O': 0.0003749531308586427, 'I-neutral,O': 0.6995073891625616, \"It's,O\": 0.0014998125234345708, 'B-negative,O': 0.6728971962616822, 'O,B-positive': 0.006374203224596925, 'B-positive,B-positive': 0.0375, 'wine,B-positive': 0.0375, 'START,B-positive': 0.003745318352059925, 'B-positive,I-positive': 0.15, 'O,I-neutral': 0.0074990626171728535, 'O,B-neutral': 0.006749156355455568, 'We,O': 0.004874390701162355, 'B-neutral,O': 0.46774193548387094, 'I-negative,B-positive': 0.008695652173913044, 'Believe,I-positive': 0.0013333333333333333, 'START,I-positive': 0.12734082397003746, 'have,O': 0.006374203224596925, 'B-positive,I-neutral': 0.075, 'Compared,I-positive': 0.0013333333333333333, 'It,O': 0.0026246719160104987, 'the,O': 0.05699287589051369, 'This,O': 0.005249343832020997, 'I,O': 0.0307461567304087, 'concluded,I-positive': 0.0013333333333333333, 'Not,O': 0.0011248593925759281, 'review,O': 0.0011248593925759281, 'I-positive,B-neutral': 0.009333333333333334, 'I-negative,I-positive': 0.33043478260869563, 'I-negative,B-negative': 0.02608695652173913, 'B-neutral,I-neutral': 0.08064516129032258, 'I-neutral,B-negative': 0.029556650246305417, \"I'll,O\": 0.0007499062617172854, 'Good,O': 0.0007499062617172854, 'I-positive,STOP': 0.005333333333333333, 'lox,I-positive': 0.0013333333333333333, 'Although,O': 0.0003749531308586427, \"We've,O\": 0.0003749531308586427, 'Beautiful,I-positive': 0.0013333333333333333, 'drink,O': 0.0022497187851518562, 'There,O': 0.0014998125234345708, 'I-negative,I-neutral': 0.06086956521739131, 'And,O': 0.0007499062617172854, 'this,O': 0.01124859392575928, 'B-negative,B-neutral': 0.018691588785046728, 'location,B-neutral': 0.03225806451612903, 'literally,I-positive': 0.0026666666666666666, 'B-negative,I-negative': 0.037383177570093455, 'I-negative,I-negative': 0.02608695652173913, 'place,B-negative': 0.308411214953271, 'START,B-negative': 0.0, 'Also,O': 0.0003749531308586427, 'stuff,I-negative': 0.008695652173913044, 'START,I-negative': 0.003745318352059925, 'You,O': 0.0007499062617172854, 'definately,I-positive': 0.0013333333333333333, 'lamb,B-positive': 0.0125, 'Great,O': 0.0026246719160104987, 'To,O': 0.0007499062617172854, 'refused,I-positive': 0.0013333333333333333, 'naan,I-positive': 0.0013333333333333333, 'Fabulous,I-positive': 0.0026666666666666666, 'I-neutral,I-negative': 0.029556650246305417, 'Single,I-positive': 0.0013333333333333333, 'Inside,I-positive': 0.0013333333333333333, 'However,O': 0.0007499062617172854, 'Go,I-negative': 0.017391304347826087, 'B-positive,B-negative': 0.05, 'one,O': 0.0029996250468691415, \"I'm,O\": 0.0003749531308586427, 'a,O': 0.031496062992125984, 'food,B-neutral': 0.31451612903225806, 'Mmm,I-positive': 0.0013333333333333333, 'But,O': 0.0011248593925759281, 'staff,B-negative': 0.056074766355140186, 'Indian,B-neutral': 0.024193548387096774, 'B-neutral,B-neutral': 0.10483870967741936, 'As,O': 0.0014998125234345708, 'draft,I-positive': 0.0013333333333333333, 'went,O': 0.0026246719160104987, 'wait,B-neutral': 0.04838709677419355, 'is,O': 0.02249718785151856, 'last,O': 0.0014998125234345708, 'Quite,I-positive': 0.0013333333333333333, 'If,O': 0.0014998125234345708, 'never,O': 0.0018747656542932134, 'family,B-positive': 0.0375, 'With,O': 0.0003749531308586427, 'What,O': 0.0007499062617172854, 'friend,O': 0.0014998125234345708, 'rest,I-positive': 0.0026666666666666666, 'Much,I-positive': 0.0013333333333333333, 'Best,O': 0.0007499062617172854, 'I-neutral,STOP': 0.0049261083743842365, 'Trust,I-positive': 0.0013333333333333333, 'where,O': 0.0014998125234345708, 'undoubtedly,I-positive': 0.0013333333333333333, 'husband,O': 0.0007499062617172854, 'asked,O': 0.0011248593925759281, 'am,O': 0.0022497187851518562, 'These,I-positive': 0.0013333333333333333, 'After,O': 0.0007499062617172854, 'was,O': 0.025871766029246346, 'and,I-neutral': 0.5615763546798029, 'START,I-neutral': 0.0, 'wife,O': 0.0003749531308586427, 'stumbled,I-positive': 0.005333333333333333, '?,O': 0.0029996250468691415, 'absolutely,O': 0.0007499062617172854, 'put,O': 0.0011248593925759281, 'do,O': 0.0026246719160104987, 'lobster,B-neutral': 0.008064516129032258, 'i,O': 0.0022497187851518562, 'Very,O': 0.0003749531308586427, 'Try,O': 0.0007499062617172854, 'Rather,I-positive': 0.0013333333333333333, 'B-negative,B-negative': 0.018691588785046728, 'In,O': 0.0014998125234345708, 'exceedingly,I-positive': 0.0013333333333333333, 'She,O': 0.0007499062617172854, 'Went,O': 0.0011248593925759281, 'know,O': 0.0018747656542932134, 'I-neutral,I-neutral': 0.029556650246305417, 'there,O': 0.0044994375703037125, 'hassle,I-positive': 0.0013333333333333333, 'must,O': 0.0007499062617172854, 'On,O': 0.0003749531308586427, 'portions,B-neutral': 0.008064516129032258, 'all,O': 0.003374578177727784, 'Love,O': 0.0007499062617172854, 'you,O': 0.013123359580052493, 'Service,B-neutral': 0.04032258064516129, 'Its,O': 0.0003749531308586427, 'to,O': 0.025121859767529058, 'average,O': 0.0011248593925759281, 'One,O': 0.0003749531308586427, 'sitting,B-negative': 0.009345794392523364, 'frizzy,I-positive': 0.0013333333333333333, \"it's,O\": 0.0011248593925759281, 'Dokebi,O': 0.0003749531308586427, 'also,O': 0.0011248593925759281, '...,O': 0.003374578177727784, 'on,O': 0.006374203224596925, 'Next,I-positive': 0.0013333333333333333, 'drinks,B-positive': 0.0625, 'Most,O': 0.0003749531308586427, 'service,B-negative': 0.14018691588785046, 'diamond,I-positive': 0.0013333333333333333, 'here,O': 0.0029996250468691415, 'line,O': 0.0003749531308586427, 'Everyone,O': 0.0003749531308586427, 'bathroom,I-negative': 0.017391304347826087, 'Schooner,I-positive': 0.004, 'pizza,I-neutral': 0.04926108374384237, 'restaurant,B-negative': 0.1308411214953271, 'For,O': 0.0011248593925759281, 'entrees,I-positive': 0.0026666666666666666, 'Again,I-positive': 0.0013333333333333333, 'Visited,I-positive': 0.0013333333333333333, 'A,O': 0.0029996250468691415, 'DONOT,I-positive': 0.0013333333333333333, 'wonderful,O': 0.0011248593925759281, 'Worth,I-positive': 0.0013333333333333333, 'B-neutral,STOP': 0.008064516129032258, \"I've,O\": 0.0014998125234345708, 'servers,B-negative': 0.009345794392523364, 'were,O': 0.006749156355455568, 'recommend,O': 0.0014998125234345708, 'sinful,I-positive': 0.0013333333333333333, 'real,O': 0.0003749531308586427, 'Al,I-positive': 0.0013333333333333333, 'I-negative,STOP': 0.008695652173913044, 'only,O': 0.0026246719160104987, 'highly,O': 0.0003749531308586427, 'Their,O': 0.0003749531308586427, 'thanked,I-positive': 0.0013333333333333333, 'Sometimes,I-positive': 0.0013333333333333333, 'courteous,I-positive': 0.0026666666666666666, 'prices,O': 0.0011248593925759281, 'are,O': 0.007124109486314211, 'duck,I-positive': 0.0013333333333333333, 'love,O': 0.0011248593925759281, 'probably,O': 0.0007499062617172854, 'has,O': 0.003374578177727784, 'reservations,O': 0.0007499062617172854, ',,O': 0.046869141357330335, 'I-negative,B-neutral': 0.008695652173913044, 'establishment,B-positive': 0.05, 'Japanese,B-negative': 0.018691588785046728, 'people,B-positive': 0.05, 'please,O': 0.0003749531308586427, 'Hands,I-positive': 0.0013333333333333333, 'anti-pasta,I-positive': 0.0013333333333333333, 'Told,I-positive': 0.0013333333333333333, 'Amazing,I-positive': 0.0013333333333333333, 'because,O': 0.0018747656542932134, 'soup,I-negative': 0.017391304347826087, 'AVOID,I-positive': 0.0026666666666666666, 'B-negative,STOP': 0.009345794392523364, 'of,I-neutral': 0.2857142857142857, 'Outside,I-positive': 0.0013333333333333333, 'took,O': 0.0011248593925759281, 'survice,I-positive': 0.0013333333333333333, 'fresh,B-positive': 0.0375, 'cannot,O': 0.0003749531308586427, 'Even,O': 0.0007499062617172854, 'did,O': 0.0007499062617172854, 'been,O': 0.0014998125234345708, 'mussels,I-positive': 0.0013333333333333333, 'Yes,O': 0.0003749531308586427, 'nice,O': 0.0026246719160104987, 'it,O': 0.018747656542932135, 'Our,O': 0.0003749531308586427, 'for,O': 0.015748031496062992, 'student,I-positive': 0.0013333333333333333, 'great,O': 0.007124109486314211, 'wish,O': 0.0007499062617172854, 'consistent,O': 0.0003749531308586427, \"Rao's,I-positive\": 0.0013333333333333333, 'I-neutral,B-neutral': 0.0049261083743842365, 'B-neutral,I-negative': 0.04032258064516129, 'each,O': 0.0007499062617172854, 'Considering,I-positive': 0.0013333333333333333, 'perfect,O': 0.0011248593925759281, \"There's,I-positive\": 0.0013333333333333333, 'an,O': 0.0018747656542932134, 'though,O': 0.0026246719160104987, 'cream,I-positive': 0.0013333333333333333, '!,O': 0.01537307836520435, 'repeat,I-positive': 0.0013333333333333333, 'Girlfriend,I-positive': 0.0013333333333333333, 'Indoor,I-positive': 0.0013333333333333333, 'atmosphere,B-neutral': 0.04032258064516129, 'Pastrami,I-positive': 0.0013333333333333333, 'Cypriot,I-positive': 0.0013333333333333333, 'nicest,I-positive': 0.0013333333333333333, 'two,O': 0.0022497187851518562, 'cool,O': 0.0007499062617172854, 'lives,I-positive': 0.0013333333333333333, 'menu,I-neutral': 0.024630541871921183, 'fact,O': 0.0003749531308586427, 'Guaranteed,I-positive': 0.0013333333333333333, 'little,O': 0.0014998125234345708, 'roommate,I-positive': 0.0013333333333333333, 'but,O': 0.007874015748031496, 'hot,B-positive': 0.0125, 'clear,I-positive': 0.0013333333333333333, 'thought,O': 0.0003749531308586427, 'prepared,O': 0.0003749531308586427, 'best,O': 0.0029996250468691415, 'night,I-positive': 0.004, 'then,O': 0.0011248593925759281, 'heard,O': 0.0007499062617172854, 'got,O': 0.0022497187851518562, 'that,O': 0.010873640794900637, 'short,I-positive': 0.0026666666666666666, 'usual,I-positive': 0.0013333333333333333, 'upon,O': 0.0011248593925759281, 'think,O': 0.0022497187851518562, 'financial,I-positive': 0.0013333333333333333, 'keep,O': 0.0014998125234345708, 'AMAZING,O': 0.0003749531308586427, \"I'd,O\": 0.0003749531308586427, 'hair,I-positive': 0.0013333333333333333, 'bagels,B-positive': 0.0125, 'six,I-positive': 0.0013333333333333333, 'very,O': 0.006374203224596925, 'had,O': 0.0074990626171728535, 'Friendly,I-positive': 0.0013333333333333333, 'overpriced,O': 0.0014998125234345708, \"Can't,O\": 0.0003749531308586427, 'ended,I-positive': 0.0026666666666666666, 'pork,I-negative': 0.02608695652173913, \"Baluchi's,I-positive\": 0.0013333333333333333, 'reluctant,I-positive': 0.0013333333333333333, 'be,O': 0.00562429696287964, 'Terrible,I-positive': 0.0013333333333333333, 'so,O': 0.007124109486314211, 'kind,O': 0.0007499062617172854, 'group,O': 0.0007499062617172854, 'actually,O': 0.0014998125234345708, 'spectacular,O': 0.0007499062617172854, 'Other,I-positive': 0.0013333333333333333, 'kafta,I-positive': 0.0013333333333333333, '.,O': 0.08286464191976003, 'quaint,I-positive': 0.0013333333333333333, 'steak,I-negative': 0.008695652173913044, 'three,O': 0.0003749531308586427, 'prompt,O': 0.0007499062617172854, 'limited,I-positive': 0.004, 'jus,I-positive': 0.0013333333333333333, 'most,O': 0.0014998125234345708, 'by,I-negative': 0.08695652173913043, 'Will,O': 0.0003749531308586427, 'really,O': 0.0018747656542932134, 'east,B-positive': 0.0125, 'fine,O': 0.0007499062617172854, 'Quick,I-positive': 0.0013333333333333333}\n"
     ]
    }
   ],
   "source": [
    "#store transition end emission probabilities\n",
    "probabilitydict={}\n",
    "start=0\n",
    "for i in range(len(modifiedEN_train_list)):\n",
    "    k=modifiedEN_train_list[i]\n",
    "    if k==\"\":\n",
    "        start=0\n",
    "    else:\n",
    "        k=k.split(\" \")\n",
    "        word=k[0]\n",
    "        tag=k[1]\n",
    "        key=k[0]+\",\"+k[1]\n",
    "        #print(i[1])\n",
    "        #calulate transition at start\n",
    "        if start==0:\n",
    "            previoustag=\"START\"\n",
    "            if key in probabilitydict:\n",
    "                pass\n",
    "            else:\n",
    "                probabilitydict[key]=estimate_emission_fix(word,tag)\n",
    "                start=1\n",
    "        transition=previoustag+\",\"+tag\n",
    "        if modifiedEN_train_list[i+1]==\"\":\n",
    "            transit=tag+\",\"+\"STOP\"\n",
    "            if transit in probabilitydict:\n",
    "                pass\n",
    "            else:\n",
    "                probabilitydict[transit]=estimate_transition(\"STOP\",tag)\n",
    "        elif transition in probabilitydict:\n",
    "            pass\n",
    "        else:\n",
    "            probabilitydict[transition]=estimate_transition(tag,previoustag)\n",
    "        previoustag=k[1]\n",
    "    #do for stop case\n",
    "        \n",
    "    \n",
    "print(probabilitydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prob(i,u):\n",
    "    # base case\n",
    "    if i == 1:\n",
    "        a = transition from start to u\n",
    "        return a\n",
    "    # recursive case\n",
    "    else:\n",
    "        forward_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if probabilitydict.get(v+\",\"+u) != None and probabilitydict.get(v+\",\"+word at u) != None:\n",
    "                a = probabilitydict[v+\",\"+u]#transition from v to u #read from dict\n",
    "                b = probabilitydict[v+\",\"+word at u]#emission from v to xi #read from dict\n",
    "                forward_prob_from_v = forward_prob(i-1, v)*a*b\n",
    "                forward_prob_list.append(forward_prob_from_v)\n",
    "        return sum(forward_prob_list)\n",
    "    \n",
    "def back_prob(i,u, lengthOfSentence):\n",
    "    n = lengthOfSentence\n",
    "    # base case\n",
    "    if i == n:\n",
    "        a = transition from u to stop\n",
    "        b = emission from u to xn\n",
    "        return a*b\n",
    "    # recursive case\n",
    "    else:\n",
    "        back_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if probabilitydict.get(u+\",\"+v) != None and probabilitydict.get(u+\",\"+word at u) != None:\n",
    "                a = transition from u to v\n",
    "                b = emission from u to xi\n",
    "                back_prob_from_v = back_prob(i + 1, v, n) * a * b\n",
    "                back_prob_list.append(forward_prob_from_v)\n",
    "        return sum(back_prob_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_marginal(sentence):\n",
    "    #sentence is a list containing the words\n",
    "    # this is only for one sentence\n",
    "    opti_path = []\n",
    "    for i in range(1, len(sentence) + 1):\n",
    "        opti_y_dict = {}\n",
    "        for tag in all_tags:\n",
    "            opti_y_at_i = forward_prob(i,tag)*back_prob(i,tag, len(sentence))\n",
    "            opti_y_dict[tag] = opti_y_at_i\n",
    "        max_i_path = argmax(opti_y_dict)\n",
    "        opti_path.append(max_i_path)\n",
    "        \n",
    "    return opti_path\n",
    "\n",
    "# dev_in_list is a giant list\n",
    "# do a split according to \"\"\n",
    "for sentence in sentences:\n",
    "    max_marginal(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def factorial(n):\n",
    "\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "print(factorial(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
