{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads dev.in as a list, and separates each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 24242, 'I-positive': 607, 'B-positive': 1208, 'I-negative': 133, 'B-negative': 382, 'I-neutral': 23, 'B-neutral': 65}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "    \n",
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "def split_into_sentences(dev_in_list):\n",
    "    sentences = []\n",
    "    each_sentence = []\n",
    "    for word in dev_in_list:\n",
    "        if word == \"\":\n",
    "            sentences.append(each_sentence)\n",
    "            each_sentence = []\n",
    "        else:\n",
    "            each_sentence.append(word)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "modified_train_list = load_modified_train_file()   \n",
    "dev_in_list = load_files()\n",
    "sentences = split_into_sentences(dev_in_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giant Emission and Giant Transition Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0054038445672799276\n"
     ]
    }
   ],
   "source": [
    "def count_word_tag_pair_dict():\n",
    "    word_tag_pair_dict= {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair_dict.get(word_tag_pair) == None:\n",
    "            word_tag_pair_dict[word_tag_pair] = 1\n",
    "        else:\n",
    "            word_tag_pair_dict[word_tag_pair] += 1\n",
    "    return word_tag_pair_dict\n",
    "\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "\n",
    "def store_estimate_emission_fix():\n",
    "    giantEmissionDict = {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair != \"\":\n",
    "            word_tag_pair_list = word_tag_pair.split(\" \")\n",
    "            countTop = wordTagPairDict[word_tag_pair]\n",
    "            countBottom = annotationDict[word_tag_pair_list[1]]\n",
    "            emission = countTop/countBottom\n",
    "            if giantEmissionDict.get(word_tag_pair) == None:\n",
    "                giantEmissionDict[word_tag_pair] = countTop/countBottom\n",
    "    return giantEmissionDict\n",
    "\n",
    "def store_estimate_transition():\n",
    "    giantTransitionDict = {}\n",
    "    finalGiantTransitionDict = {}\n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if giantTransitionDict.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "    for eachTransition in giantTransitionDict:\n",
    "        eachTransitionList = eachTransition.split(\" \")\n",
    "        startState = eachTransitionList[0]\n",
    "        countTop = giantTransitionDict[eachTransition]\n",
    "        countBottom = totalStateNumber[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        finalGiantTransitionDict[eachTransition] = transitionParam\n",
    "        \n",
    "    return finalGiantTransitionDict\n",
    "\n",
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    totalStateNumber = {}\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    \n",
    "    for each_tweet in giant_each_tweet:\n",
    "        for tag in each_tweet:\n",
    "            if totalStateNumber.get(tag) == None:\n",
    "                totalStateNumber[tag] = 1\n",
    "            else:\n",
    "                totalStateNumber[tag] += 1\n",
    "\n",
    "    return giant_each_tweet, countStart, totalStateNumber\n",
    "\n",
    "modifiedWordDict = get_word_dict()\n",
    "wordTagPairDict = count_word_tag_pair_dict()\n",
    "giantEmissionDict = store_estimate_emission_fix()\n",
    "giantTaggedEachTweet, countStart, totalStateNumber = separate_tweets()\n",
    "print(giantEmissionDict[\"are O\"])\n",
    "giantTransitionDict = store_estimate_transition()\n",
    "# print(giantTransitionDict)\n",
    "# print(len(giantTransitionDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prob(i,u, sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    last_word = sentence[len(sentence)-1]\n",
    "    # base case\n",
    "    if i == 1:\n",
    "        if giantTransitionDict.get(\"START\" + \" \" + u) != None:\n",
    "            a = giantTransitionDict[\"START\" + \" \" + u]#transition from start to u\n",
    "            return a\n",
    "#         else:\n",
    "# #             print(u)\n",
    "#             return 0\n",
    "    # recursive case\n",
    "    else:\n",
    "        word_at_u = sentence[i]\n",
    "        if word_at_u in modifiedWordDict:\n",
    "            word_at_u = word_at_u\n",
    "        else:\n",
    "            word_at_u = \"#UNK#\"\n",
    "        forward_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if giantTransitionDict.get(v + \" \"+ u) != None and giantEmissionDict.get(word_at_u+\" \"+v ) != None:\n",
    "                a = giantTransitionDict[v +\" \"+ u]#transition from v to u #read from dict\n",
    "                b = giantEmissionDict[word_at_u + \" \"+ v]#emission from v to xi #read from dict\n",
    "                forward_prob_from_v = forward_prob(i-1, v, sentence)*a*b\n",
    "                forward_prob_list.append(forward_prob_from_v)\n",
    "        print(forward_prob_list)\n",
    "        return sum(forward_prob_list)\n",
    "    \n",
    "def back_prob(i,u, sentence):\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    last_word = sentence[len(sentence)-1]\n",
    "    n = len(sentence)\n",
    "    # base case\n",
    "    if i == n:\n",
    "        if giantTransitionDict.get(u + \" \" + \"STOP\") != None and giantEmissionDict.get(last_word + \" \" + u) != None:\n",
    "            a = giantTransitionDict[u + \" \" + \"STOP\"]#transition from u to stop\n",
    "            b = giantEmissionDict[last_word + \" \" + u]#emission from u to xn\n",
    "            return a*b\n",
    "#         else:\n",
    "#             return 0\n",
    "    # recursive case\n",
    "    else:\n",
    "        word_at_u = sentence[i]\n",
    "        if word_at_u in modifiedWordDict:\n",
    "            word_at_u = word_at_u\n",
    "        else:\n",
    "            word_at_u = \"#UNK#\"\n",
    "        back_prob_list = []\n",
    "        for v in all_tags:\n",
    "            if giantTransitionDict.get(u + \" \"+ v) != None and giantEmissionDict.get(word_at_u + \" \" + u) != None:\n",
    "                a = giantTransitionDict[u + \" \" + v]#transition from u to v\n",
    "                b = giantEmissionDict[word_at_u + \" \" + u]#emission from u to xi\n",
    "                back_prob_from_v = back_prob(i + 1, v, sentence) * a * b\n",
    "                back_prob_list.append(back_prob_from_v)\n",
    "#                 print(back_prob_list)\n",
    "\n",
    "        return sum(back_prob_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_path(best_path, sentence):\n",
    "#     print(best_path)\n",
    "#     print(sentence)\n",
    "#     print(len(best_path))\n",
    "#     print(len(sentence))\n",
    "    result = \"\"\n",
    "    for i in range(len(sentence)):\n",
    "        if (sentence[i] == ''):\n",
    "            result += \" \\n\"\n",
    "        else:\n",
    "            result += sentence[i] + \" \" + best_path[i] + \"\\n\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n",
      "0.0\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "B-negative\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0.0\n",
      "[]\n",
      "[0.0]\n",
      "B-positive\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0.0\n",
      "[]\n",
      "[0.0]\n",
      "B-neutral\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0.0\n",
      "[]\n",
      "[0.0]\n",
      "I-negative\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0\n",
      "[]\n",
      "[0.0]\n",
      "I-positive\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0\n",
      "[]\n",
      "[0.0]\n",
      "I-neutral\n",
      "[]\n",
      "[0.0]\n",
      "0.0\n",
      "0\n",
      "[]\n",
      "[0.0]\n",
      "{'O': 0.0, 'B-negative': 0.0, 'B-positive': 0.0, 'B-neutral': 0.0, 'I-negative': 0.0, 'I-positive': 0.0, 'I-neutral': 0.0}\n",
      "O\n",
      "O\n",
      "0.9401709401709402\n",
      "0.0\n",
      "B-negative\n",
      "0.010683760683760684\n",
      "0.0\n",
      "B-positive\n",
      "0.0438034188034188\n",
      "0.0\n",
      "B-neutral\n",
      "0.005341880341880342\n",
      "0\n",
      "I-negative\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-96ce61157df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_marginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0msingleStringToBeWritten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingleStringToBeWritten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-96ce61157df6>\u001b[0m in \u001b[0;36mmax_marginal\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mopti_y_at_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mback_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#             print(opti_y_at_i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mopti_y_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopti_y_at_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "def max_marginal(sentence):\n",
    "    sentence.append(\"\")\n",
    "    #sentence is a list containing the words\n",
    "    # this is only for one sentence\n",
    "    opti_path = []\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    for i in range(len(sentence)):\n",
    "        opti_y_dict = {}\n",
    "        for tag in all_tags:\n",
    "            print(tag)\n",
    "            f = forward_prob(i,tag, sentence)\n",
    "            b = back_prob(i,tag, sentence)\n",
    "            print(f)\n",
    "            print(b)\n",
    "            opti_y_at_i = forward_prob(i,tag, sentence)*back_prob(i,tag, sentence)\n",
    "#             print(opti_y_at_i)\n",
    "            opti_y_dict[tag] = opti_y_at_i\n",
    "        print(opti_y_dict)\n",
    "        max_i_path = max(opti_y_dict, key=opti_y_dict.get)\n",
    "        print(max_i_path)\n",
    "        opti_path.append(max_i_path)\n",
    "    return opti_path\n",
    "\n",
    "# dev_in_list is a giant list\n",
    "# do a split according to \"\"\n",
    "# giantStringToBeWritten = \"\"\n",
    "# for sentence in sentences:\n",
    "#     singleStringToBeWritten = max_marginal(sentence)\n",
    "#     giantStringToBeWritten += singleStringToBeWritten\n",
    "giantStringToBeWritten = \"\"\n",
    "for i in range(len(sentences)):\n",
    "    if i == 1:\n",
    "        best_path = max_marginal(sentences[i])\n",
    "        singleStringToBeWritten = combine_path(best_path, sentences[i])\n",
    "        print(singleStringToBeWritten)\n",
    "        giantStringToBeWritten += singleStringToBeWritten\n",
    "print(giantStringToBeWritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
