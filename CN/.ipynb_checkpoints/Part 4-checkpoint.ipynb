{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads dev.in as a list, and separates each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 47860, 'I-positive': 1426, 'B-positive': 1135, 'I-negative': 96, 'B-negative': 111, 'I-neutral': 1369, 'B-neutral': 1350}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "    \n",
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "def split_into_sentences(dev_in_list):\n",
    "    sentences = []\n",
    "    each_sentence = []\n",
    "    for word in dev_in_list:\n",
    "        if word == \"\":\n",
    "            sentences.append(each_sentence)\n",
    "            each_sentence = []\n",
    "        else:\n",
    "            each_sentence.append(word)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "modified_train_list = load_modified_train_file()   \n",
    "dev_in_list = load_files()\n",
    "sentences = split_into_sentences(dev_in_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giant Emission and Giant Transition Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_word_tag_pair_dict():\n",
    "    word_tag_pair_dict= {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair_dict.get(word_tag_pair) == None:\n",
    "            word_tag_pair_dict[word_tag_pair] = 1\n",
    "        else:\n",
    "            word_tag_pair_dict[word_tag_pair] += 1\n",
    "    return word_tag_pair_dict\n",
    "\n",
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "\n",
    "def store_estimate_emission_fix():\n",
    "    giantEmissionDict = {}\n",
    "    for word_tag_pair in modified_train_list:\n",
    "        if word_tag_pair != \"\":\n",
    "            word_tag_pair_list = word_tag_pair.split(\" \")\n",
    "            countTop = wordTagPairDict[word_tag_pair]\n",
    "            countBottom = annotationDict[word_tag_pair_list[1]]\n",
    "            emission = countTop/countBottom\n",
    "            if giantEmissionDict.get(word_tag_pair) == None:\n",
    "                giantEmissionDict[word_tag_pair] = countTop/countBottom\n",
    "    return giantEmissionDict\n",
    "\n",
    "def store_estimate_transition():\n",
    "    giantTransitionDict = {}\n",
    "    finalGiantTransitionDict = {}\n",
    "    for taggedEachTweet in giantTaggedEachTweet:\n",
    "        for i in range(len(taggedEachTweet) - 1):\n",
    "            if giantTransitionDict.get(taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]) == None:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] = 1\n",
    "            else:\n",
    "                giantTransitionDict[taggedEachTweet[i]+\" \"+taggedEachTweet[i+1]] += 1\n",
    "    for eachTransition in giantTransitionDict:\n",
    "        eachTransitionList = eachTransition.split(\" \")\n",
    "        startState = eachTransitionList[0]\n",
    "        countTop = giantTransitionDict[eachTransition]\n",
    "        countBottom = totalStateNumber[startState]\n",
    "        transitionParam = countTop/countBottom\n",
    "        finalGiantTransitionDict[eachTransition] = transitionParam\n",
    "        \n",
    "    return finalGiantTransitionDict\n",
    "\n",
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    totalStateNumber = {}\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    \n",
    "    for each_tweet in giant_each_tweet:\n",
    "        for tag in each_tweet:\n",
    "            if totalStateNumber.get(tag) == None:\n",
    "                totalStateNumber[tag] = 1\n",
    "            else:\n",
    "                totalStateNumber[tag] += 1\n",
    "\n",
    "    return giant_each_tweet, countStart, totalStateNumber\n",
    "\n",
    "modifiedWordDict = get_word_dict()\n",
    "wordTagPairDict = count_word_tag_pair_dict()\n",
    "giantEmissionDict = store_estimate_emission_fix()\n",
    "giantTaggedEachTweet, countStart, totalStateNumber = separate_tweets()\n",
    "giantTransitionDict = store_estimate_transition()\n",
    "# print(giantTransitionDict[\"START O\"])\n",
    "# print(giantTransitionDict)\n",
    "# print(len(giantTransitionDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def forward_prob(i,u, sentence):\n",
    "#     all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "#     last_word = sentence[len(sentence)-1]\n",
    "#     # base case\n",
    "#     if i == 1:\n",
    "#         if giantTransitionDict.get(\"START\" + \" \" + u) != None:\n",
    "#             a = giantTransitionDict[\"START\" + \" \" + u]#transition from start to u\n",
    "#             return a\n",
    "#         else:\n",
    "# #             print(u)\n",
    "#             return 0\n",
    "#     # recursive case\n",
    "#     else:\n",
    "#         word_at_u = sentence[i-1]\n",
    "# #         print(word_at_u)\n",
    "#         if word_at_u in modifiedWordDict:\n",
    "#             word_at_u = word_at_u\n",
    "#         else:\n",
    "#             word_at_u = \"#UNK#\"\n",
    "#         forward_prob_list = []\n",
    "#         for v in all_tags:\n",
    "#             if giantTransitionDict.get(v + \" \"+ u) != None and giantEmissionDict.get(word_at_u+\" \"+v ) != None:\n",
    "#                 a = giantTransitionDict[v +\" \"+ u]#transition from v to u #read from dict\n",
    "#                 b = giantEmissionDict[word_at_u + \" \"+ v]#emission from v to xi #read from dict\n",
    "#                 forward_prob_from_v = forward_prob(i-1, v, sentence)*a*b\n",
    "#                 forward_prob_list.append(forward_prob_from_v)\n",
    "#         return sum(forward_prob_list)\n",
    "    \n",
    "# def back_prob(i,u, sentence):\n",
    "#     all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "#     last_word = sentence[len(sentence)-1]\n",
    "#     n = len(sentence)\n",
    "#     # base case\n",
    "#     if i == n:\n",
    "#         if giantTransitionDict.get(u + \" \" + \"STOP\") != None and giantEmissionDict.get(last_word + \" \" + u) != None:\n",
    "#             a = giantTransitionDict[u + \" \" + \"STOP\"]#transition from u to stop\n",
    "#             b = giantEmissionDict[last_word + \" \" + u]#emission from u to xn\n",
    "#             return a*b\n",
    "#         else:\n",
    "#             return 0\n",
    "#     # recursive case\n",
    "#     else:\n",
    "#         word_at_v = sentence[i]\n",
    "#         if word_at_v in modifiedWordDict:\n",
    "#             word_at_v = word_at_v\n",
    "#         else:\n",
    "#             word_at_v = \"#UNK#\"\n",
    "#         back_prob_list = []\n",
    "#         for v in all_tags:\n",
    "#             if i == 1:\n",
    "#                 v = \"START\"\n",
    "#             if giantTransitionDict.get(u + \" \"+ v) != None and giantEmissionDict.get(word_at_v + \" \" + u) != None:\n",
    "#                 a = giantTransitionDict[u + \" \" + v]#transition from u to v\n",
    "#                 b = giantEmissionDict[word_at_v + \" \" + u]#emission from u to xi\n",
    "#                 back_prob_from_v = back_prob(i + 1, v, sentence) * a * b\n",
    "#                 back_prob_list.append(back_prob_from_v)\n",
    "# #                 print(back_prob_list)\n",
    "\n",
    "#         return sum(back_prob_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_path(best_path, sentence):\n",
    "    result = \"\"\n",
    "    sentence.append(\"\")\n",
    "    for i in range(len(sentence)):\n",
    "        if (sentence[i] == ''):\n",
    "            result += \" \\n\"\n",
    "        else:\n",
    "            result += sentence[i] + \" \" + best_path[i] + \"\\n\"\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Decoding Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def max_marginal(sentence):\n",
    "#     sentence.append(\"\")\n",
    "#     #sentence is a list containing the words\n",
    "#     # this is only for one sentence\n",
    "#     opti_path = []\n",
    "#     all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "#     for i in range(len(sentence)-1): #minus 1, so you dont consider \"\"\n",
    "#         opti_y_dict = {}\n",
    "#         for tag in all_tags:\n",
    "#             print(tag)\n",
    "#             f = forward_prob(i,tag, sentence)\n",
    "#             b = back_prob(i,tag, sentence)\n",
    "#             opti_y_at_i = f*b\n",
    "#             opti_y_dict[tag] = opti_y_at_i\n",
    "#             print(opti_y_dict)\n",
    "#         max_i_path = max(opti_y_dict, key=opti_y_dict.get)\n",
    "\n",
    "#         opti_path.append(max_i_path)\n",
    "#     return opti_path\n",
    "\n",
    "# shortSentence = ['The', 'tuna', 'and', '#UNK#', 'potatoes', 'are', 'excellent', '.']\n",
    "# max_marginal(shortSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Decoding Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_marginal(sentence):\n",
    "    opti_path = []\n",
    "    all_tags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "    forward = {}\n",
    "    alpha_base = {}\n",
    "    for u in all_tags:\n",
    "        if giantTransitionDict.get(\"START\" + \" \" + u) != None:\n",
    "            alpha_base[u] = giantTransitionDict[\"START\" + \" \" + u]\n",
    "        else:\n",
    "            alpha_base[u] = 0.0\n",
    "    forward[0] = alpha_base\n",
    "    for i in range(len(sentence)): #0 ... 7\n",
    "        if sentence[i] in modifiedWordDict:\n",
    "            sentence[i] = sentence[i]\n",
    "        else:\n",
    "            sentence[i] = \"#UNK#\"\n",
    "            \n",
    "        tempAlpha = {}\n",
    "        for u in all_tags:\n",
    "            alpha = 0.0\n",
    "            for v in all_tags:\n",
    "                a = 0.0\n",
    "                b = 0.0\n",
    "                if giantTransitionDict.get(v + \" \" + u) != None:\n",
    "                    a = giantTransitionDict[v + \" \" + u]\n",
    "                if giantEmissionDict.get(sentence[i] + \" \" + v) != None:\n",
    "                    b = giantEmissionDict[sentence[i] + \" \" + v]\n",
    "                alpha += float(forward[i][v] * a * b)\n",
    "            tempAlpha[u] = alpha\n",
    "        forward[i + 1] = tempAlpha\n",
    "    \n",
    "    lastWord = sentence[len(sentence)-1] #last word \n",
    "    if lastWord in modifiedWordDict:\n",
    "        lastWord = lastWord\n",
    "    else:\n",
    "        lastWord = \"#UNK#\"\n",
    "    backwards = {} \n",
    "    beta_base = {}\n",
    "    for u in all_tags:\n",
    "        transition_v = 0.0 \n",
    "        emission_v = 0.0 \n",
    "        if giantTransitionDict.get(u + \" \" + \"STOP\") != None:\n",
    "            transition_v = giantTransitionDict[u + \" \" + \"STOP\"]\n",
    "        if giantEmissionDict.get(lastWord + \" \" + u) != None:\n",
    "            emission_v = giantEmissionDict[lastWord + \" \" + u]\n",
    "        beta_base[u] = float(transition_v * emission_v)\n",
    "    backwards[len(sentence)] = beta_base #key is 8\n",
    "    for i in range(len(sentence), 0, -1): #8, .... 1\n",
    "        i = i -1\n",
    "        if sentence[i] in modifiedWordDict:\n",
    "            sentence[i] = sentence[i]\n",
    "        else:\n",
    "            sentence[i] = \"#UNK#\"\n",
    "            \n",
    "        tempBeta = {}\n",
    "        for u in all_tags:\n",
    "            beta = 0.0\n",
    "            for v in all_tags:\n",
    "                a = 0.0\n",
    "                b = 0.0\n",
    "                if giantTransitionDict.get(u + \" \" + v) != None:\n",
    "                    a = giantTransitionDict[u + \" \" + v]\n",
    "                if giantEmissionDict.get(sentence[i] + \" \" + u) != None:\n",
    "                    b = giantEmissionDict[sentence[i] + \" \" + u]\n",
    "                beta += float(backwards[i+1][v]*a*b)                \n",
    "            tempBeta[u] = beta\n",
    "        backwards[i] = tempBeta\n",
    "    for j in range(len(sentence)):\n",
    "        temp = {}\n",
    "        for u in all_tags:\n",
    "            temp[u] = forward[j][u] * backwards[j][u]\n",
    "        opti_path.append(max(temp,key=temp.get))\n",
    "    return opti_path\n",
    "\n",
    "# max_marginal([\"The\", \"tuna\", \"and\", \"wasabe\", \"potatoes\", \"are\", \"excellent\", \".\"])\n",
    "giantStringToBeWritten = \"\"\n",
    "for sentence in sentences:\n",
    "    best_path = max_marginal(sentence)\n",
    "    singleStringToBeWritten = combine_path(best_path, sentence)\n",
    "    giantStringToBeWritten += singleStringToBeWritten\n",
    "f = open(\"dev.p4.out\",\"w+\")\n",
    "f.write(giantStringToBeWritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
