{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary containing the occurrences of each annotation in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_original_train():\n",
    "    with open(\"train\", encoding=\"utf-8\") as file:\n",
    "        train_list = file.readlines()\n",
    "        train_list = [x.strip() for x in train_list]\n",
    "        return train_list\n",
    "    \n",
    "train_list = load_original_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 91753, 'I-positive': 1653, 'B-positive': 2613, 'I-negative': 443, 'B-negative': 1299, 'I-neutral': 5272, 'B-neutral': 5722}\n"
     ]
    }
   ],
   "source": [
    "annotationDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    annotated_word = train_list[i]\n",
    "    each_word = annotated_word.split(\" \")\n",
    "    if (len(each_word) == 2):\n",
    "        if each_word[1] == \"O\":\n",
    "            annotationDict[\"O\"] += 1\n",
    "        elif each_word[1] == \"I-positive\":\n",
    "            annotationDict[\"I-positive\"] += 1\n",
    "        elif each_word[1] == \"B-positive\":\n",
    "            annotationDict[\"B-positive\"] += 1\n",
    "        elif each_word[1] == \"I-negative\":\n",
    "            annotationDict[\"I-negative\"] += 1\n",
    "        elif each_word[1] == \"B-negative\":\n",
    "            annotationDict[\"B-negative\"] += 1\n",
    "        elif each_word[1] == \"I-neutral\":\n",
    "            annotationDict[\"I-neutral\"] += 1\n",
    "        elif each_word[1] == \"B-neutral\":\n",
    "            annotationDict[\"B-neutral\"] += 1\n",
    "\n",
    "print(annotationDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Write a function that estimates the emission parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001198870881606051"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_emission(word, tag):\n",
    "    countTop = 0\n",
    "    countBottom = annotationDict[tag]\n",
    "    for i in range(len(train_list)):\n",
    "        annotated_word = train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if len(each_word) == 2:\n",
    "            if (each_word[0] == word and each_word[1] == tag):\n",
    "                countTop += 1\n",
    "\n",
    "#         print(countTop)\n",
    "#         print(countBottom)\n",
    "    return countTop/countBottom\n",
    "\n",
    "estimate_emission(\"service\", \"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Replace the words that appear less than k times in the training set with a special token #UNK# before training. This leads to a “modified training set”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:36.287896\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def modify_trainingset(k):\n",
    "        wordCountDict = {}\n",
    "        for i in range(len(train_list)):\n",
    "            annotated_word = train_list[i]\n",
    "            each_word = annotated_word.split(\" \")\n",
    "            if each_word[0] in wordCountDict:\n",
    "                wordCountDict[each_word[0]] += 1\n",
    "            else:\n",
    "                wordCountDict[each_word[0]] = 1\n",
    "        \n",
    "       \n",
    "        wordToBeReplacedDict = {}\n",
    "        for key in wordCountDict:\n",
    "            if wordCountDict[key] < k:\n",
    "                wordToBeReplacedDict[key] = wordCountDict[key]\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        for i in range(len(train_list)):\n",
    "            annotated_word = train_list[i]\n",
    "            each_word = annotated_word.split(\" \")\n",
    "            for key in wordToBeReplacedDict:\n",
    "                if each_word[0] == key:\n",
    "                    train_list[i] = \"#UNK# \" + each_word[1]\n",
    "\n",
    "        modifiedTotalTrainSet = \"\\n\".join(train_list)\n",
    "\n",
    "        f = open(\"modified_train\",\"w+\")\n",
    "        f.write(modifiedTotalTrainSet)\n",
    "                            \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        print(elapsed)\n",
    "            \n",
    "\n",
    "    \n",
    "modify_trainingset(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_modified_train_file():\n",
    "    with open(\"modified_train\", encoding=\"utf-8\") as file:\n",
    "        modified_train_list = file.readlines()\n",
    "        modified_train_list = [x.strip() for x in modified_train_list]\n",
    "        return modified_train_list\n",
    "        \n",
    "modified_train_list = load_modified_train_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_dict():\n",
    "    modifiedWordDict = {}        \n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word[0] in modifiedWordDict:\n",
    "            modifiedWordDict[each_word[0]] += 1\n",
    "        else:\n",
    "            modifiedWordDict[each_word[0]] = 1\n",
    "\n",
    "    return modifiedWordDict\n",
    "    \n",
    "modifiedWordDict = get_word_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_emission_fix(word, tag):\n",
    "        countTop = 0\n",
    "        countBottom = annotationDict[tag]\n",
    "        if word in modifiedWordDict:\n",
    "            # do nothing\n",
    "            word = word\n",
    "            \n",
    "        else:\n",
    "            word = \"#UNK#\"\n",
    "            \n",
    "        for i in range(len(modified_train_list)):\n",
    "            annotated_word = modified_train_list[i]\n",
    "            each_word = annotated_word.split(\" \")\n",
    "            if (each_word[0] == word and each_word[1] == tag):\n",
    "                countTop += 1\n",
    "#         print('emission')\n",
    "#         print(countTop)\n",
    "        return countTop/countBottom\n",
    "\n",
    "estimate_emission_fix(\"When\", \"B-negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Implement a simple sentiment analysis system that produces the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I-positive'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment_analysis(word):\n",
    "    OScore = estimate_emission_fix(word, \"O\")\n",
    "    BPlusScore = estimate_emission_fix(word, \"B-positive\")\n",
    "    IPlusScore = estimate_emission_fix(word, \"I-positive\")\n",
    "    BMinusScore = estimate_emission_fix(word, \"B-negative\")\n",
    "    IMinusScore = estimate_emission_fix(word, \"I-negative\")\n",
    "    BNeutralScore = estimate_emission_fix(word, \"B-neutral\")\n",
    "    INeutralScore = estimate_emission_fix(word, \"I-neutral\")\n",
    "\n",
    "    scoreDict = {\"O\": OScore, \"I-positive\": IPlusScore, \"B-positive\": BPlusScore, \"I-negative\":IMinusScore, \"B-negative\": BMinusScore, \"I-neutral\":INeutralScore, \"B-neutral\":BNeutralScore}\n",
    "    maximumScore = max(scoreDict.values())\n",
    "    return max(scoreDict, key=scoreDict.get)\n",
    "\n",
    "   \n",
    "sentiment_analysis(\"service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    with open(\"dev.in\", encoding=\"utf-8\") as file:\n",
    "        dev_in_list = file.readlines()\n",
    "        dev_in_list = [x.strip() for x in dev_in_list]\n",
    "        return dev_in_list\n",
    "        \n",
    "dev_in_list = load_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . 0:06:27.978423\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def predict_sentiment():\n",
    "    wordDict = {}\n",
    "    f = open(\"dev.final.out\",\"w+\")\n",
    "    giantStringToBeWritten = \"\"\n",
    "    start = datetime.datetime.now()\n",
    "    for i in range(len(dev_in_list)):\n",
    "        each_word = dev_in_list[i]\n",
    "        if (i > 4300):\n",
    "            print(\". \",end=\"\")\n",
    "        if each_word in wordDict:\n",
    "            tag = wordDict[each_word]\n",
    "            giantStringToBeWritten += each_word +  \" \" + tag + \"\\n\"\n",
    "#             f.write(each_word +  \" \" + tag + \"\\n\")\n",
    "        else:\n",
    "            if each_word != \"\":\n",
    "                tag = sentiment_analysis(each_word)\n",
    "                wordDict[each_word] = tag \n",
    "                giantStringToBeWritten += each_word +  \" \" + tag + \"\\n\"\n",
    "#                 f.write(each_word +  \" \" + tag + \"\\n\")\n",
    "            else:\n",
    "                giantStringToBeWritten += \" \\n\"\n",
    "#                 f.write(\" \\n\")\n",
    "\n",
    "    f.write(giantStringToBeWritten)\n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)\n",
    "\n",
    "predict_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 3 \n",
    "#### Function to estimate Transition Parameters using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_tweets():\n",
    "    countStart = 1\n",
    "    countBottom = 0\n",
    "    countTop = 0\n",
    "    # counting starts\n",
    "    giant_each_tweet = []\n",
    "    each_tweet = []\n",
    "    for i in range(len(modified_train_list)):\n",
    "        annotated_word = modified_train_list[i]\n",
    "        each_word = annotated_word.split(\" \")\n",
    "        if each_word == ['']:\n",
    "            countStart += 1\n",
    "            giant_each_tweet.append(each_tweet)\n",
    "            each_tweet = []\n",
    "\n",
    "        else:\n",
    "            each_tweet.append(each_word[1])\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        giant_each_tweet[i].insert(0, 'START')\n",
    "        giant_each_tweet[i].append('STOP')\n",
    "    return giant_each_tweet, countStart\n",
    "giant_each_tweet, countStart = separate_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8731322244149986"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_transition(current_tag, previous_tag):\n",
    "#     with open(\"modified_train_final2\", encoding=\"utf-8\") as file:\n",
    "    startDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        each_tweet = giant_each_tweet[i]\n",
    "        if each_tweet[1] == \"O\":\n",
    "            startDict[\"O\"] += 1\n",
    "        elif each_tweet[1] == \"I-positive\":\n",
    "            startDict[\"I-positive\"] += 1\n",
    "        elif each_tweet[1] == \"B-positive\":\n",
    "            startDict[\"B-positive\"] += 1\n",
    "        elif each_tweet[1] == \"I-negative\":\n",
    "            startDict[\"I-negative\"] += 1\n",
    "        elif each_tweet[1] == \"B-negative\":\n",
    "            startDict[\"B-negative\"] += 1\n",
    "        elif each_tweet[1] == \"I-neutral\":\n",
    "            startDict[\"I-neutral\"] += 1\n",
    "        elif each_tweet[1] == \"B-neutral\":\n",
    "            startDict[\"B-neutral\"] += 1\n",
    "\n",
    "    stopDict = {\"O\": 0, \"I-positive\": 0, \"B-positive\": 0, \"I-negative\":0, \"B-negative\": 0, \"I-neutral\":0, \"B-neutral\":0}\n",
    "    for i in range(len(giant_each_tweet)):\n",
    "        each_tweet = giant_each_tweet[i]\n",
    "        last_index = len(each_tweet) - 2\n",
    "        if each_tweet[last_index] == \"O\":\n",
    "            stopDict[\"O\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-positive\":\n",
    "            stopDict[\"I-positive\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-positive\":\n",
    "            stopDict[\"B-positive\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-negative\":\n",
    "            stopDict[\"I-negative\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-negative\":\n",
    "            stopDict[\"B-negative\"] += 1\n",
    "        elif each_tweet[last_index] == \"I-neutral\":\n",
    "            stopDict[\"I-neutral\"] += 1\n",
    "        elif each_tweet[last_index] == \"B-neutral\":\n",
    "            stopDict[\"B-neutral\"] += 1\n",
    "\n",
    "    if previous_tag == \"START\":\n",
    "        # current tag is Yn\n",
    "        countTop = startDict[current_tag]\n",
    "#             print(countTop)\n",
    "#             print(countStart)\n",
    "#             print(countTop/countStart)\n",
    "        return countTop/countStart\n",
    "\n",
    "    elif current_tag == \"STOP\":\n",
    "        # previous tag is Yn\n",
    "        countTop = stopDict[previous_tag]\n",
    "        countBottom = annotationDict[previous_tag]\n",
    "        return countTop/countBottom\n",
    "\n",
    "    else:\n",
    "        giantTransitionDict = {}\n",
    "        for i in range(len(giant_each_tweet)):\n",
    "            each_tweet = giant_each_tweet[i]\n",
    "            for j in range(1,len(each_tweet)-1):\n",
    "                if j == len(each_tweet):\n",
    "                    break\n",
    "                if each_tweet[j-1] == previous_tag and each_tweet[j] == \"O\":\n",
    "                    if (previous_tag + \"O\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"O\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"O\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] == \"B-negative\":\n",
    "                    if (previous_tag + \"B-negative\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-negative\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-negative\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] == \"B-positive\":\n",
    "                    if (previous_tag + \"B-positive\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-positive\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-positive\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"B-neutral\":\n",
    "                    if (previous_tag + \"B-neutral\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"B-neutral\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"B-neutral\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-positive\":\n",
    "                    if (previous_tag + \"I-positive\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-positive\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-positive\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-negative\":\n",
    "                    if (previous_tag + \"I-negative\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-negative\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-negative\"] = 1\n",
    "\n",
    "                elif each_tweet[j] == previous_tag and each_tweet[j+1] ==\"I-neutral\":\n",
    "                    if (previous_tag + \"I-neutral\") in giantTransitionDict:\n",
    "                        giantTransitionDict[previous_tag + \"I-neutral\"] += 1\n",
    "                    else:\n",
    "                        giantTransitionDict[previous_tag + \"I-neutral\"] = 1\n",
    "#             print(giantTransitionDict)\n",
    "        if giantTransitionDict.get(previous_tag+current_tag) == None:\n",
    "            return 0\n",
    "        else:\n",
    "            countTop = giantTransitionDict[previous_tag+current_tag]\n",
    "            countBottom = annotationDict[previous_tag]\n",
    "\n",
    "            return countTop/countBottom\n",
    "\n",
    "    return 1\n",
    "\n",
    "estimate_transition(\"O\", \"START\") #current, previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI LAYER:\n",
      "[0.0004091930034968332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[[0.0004091930034968332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "MAX of 1N\n",
      "3.811760554792914e-06\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "LAYER HERE\n",
      "[3.811760554792914e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "LIST HERE\n",
      "[[0.0004091930034968332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.811760554792914e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "MAX of 1N\n",
      "8.289744603926566e-10\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "LAYER HERE\n",
      "[8.289744603926566e-10, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "LIST HERE\n",
      "[[0.0004091930034968332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.811760554792914e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.289744603926566e-10, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "MAX of 1N\n",
      "3.5831404127665697e-12\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "MAX of 1N\n",
      "0.0\n",
      "LAYER HERE\n",
      "[3.5831404127665697e-12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "LIST HERE\n",
      "[[0.0004091930034968332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.811760554792914e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.289744603926566e-10, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.5831404127665697e-12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-495dd834a8f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-495dd834a8f5>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mnList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mprevious_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malltags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_emission_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                     \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B-negative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_emission_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B-positive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mestimate_emission_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprevious_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-46d65f48f6d5>\u001b[0m in \u001b[0;36mestimate_transition\u001b[0;34m(current_tag, previous_tag)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_tweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0meach_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprevious_tag\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0meach_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprevious_tag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgiantTransitionDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                             \u001b[0mgiantTransitionDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprevious_tag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import operator\n",
    "def viterbi():\n",
    "        alltags=[\"O\",\"B-negative\",\"B-positive\",\"B-neutral\",\"I-negative\",\"I-positive\",\"I-neutral\"]\n",
    "        thetags=[]\n",
    "        piList = []\n",
    "        n=[\"start\"]\n",
    "        beginning= True\n",
    "        for i in range(len(dev_in_list)):\n",
    "#             pi1=0\n",
    "#             pi2=0\n",
    "#             pi3=0\n",
    "#             pi4=0\n",
    "#             pi5=0\n",
    "#             pi6=0\n",
    "#             pi7=0#find some way to differentriate start\n",
    "            if beginning: #base case\n",
    "                k=\"START\" #k is the starting tag\n",
    "                pi1=estimate_transition(\"O\",k)*estimate_emission_fix(dev_in_list[i],\"O\")\n",
    "                pi2=estimate_transition(\"B-negative\",k)*estimate_emission_fix(dev_in_list[i],\"B-negative\")\n",
    "                pi3=estimate_transition(\"B-positive\",k)*estimate_emission_fix(dev_in_list[i],\"B-positive\")\n",
    "                pi4=estimate_transition(\"B-neutral\",k)*estimate_emission_fix(dev_in_list[i],\"B-neutral\")\n",
    "                pi5=estimate_transition(\"I-negative\",k)*estimate_emission_fix(dev_in_list[i],\"I-negative\")\n",
    "                pi6=estimate_transition(\"I-positive\",k)*estimate_emission_fix(dev_in_list[i],\"I-positive\")\n",
    "                pi7=estimate_transition(\"I-neutral\",k)*estimate_emission_fix(dev_in_list[i],\"I-neutral\")\n",
    "                piLayer = []\n",
    "                piLayer.append(pi1)\n",
    "                piLayer.append(pi2)\n",
    "                piLayer.append(pi3)\n",
    "                piLayer.append(pi4)\n",
    "                piLayer.append(pi5)\n",
    "                piLayer.append(pi6)\n",
    "                piLayer.append(pi7)\n",
    "                piList.append(piLayer)\n",
    "                beginning = False\n",
    "                print('PI LAYER:')\n",
    "                print(piLayer)\n",
    "                print(piList)\n",
    "            else: #recursive cases\n",
    "                piLayer = []\n",
    "                for j in range(7):\n",
    "                    nList = []\n",
    "                    previous_tag = alltags[j]\n",
    "                    n1 = piList[len(piList)-1][j]*estimate_transition(\"O\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n2 = piList[len(piList)-1][j]*estimate_transition(\"B-negative\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n3 = piList[len(piList)-1][j]*estimate_transition(\"B-positive\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n4 = piList[len(piList)-1][j]*estimate_transition(\"B-neutral\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n5 = piList[len(piList)-1][j]*estimate_transition(\"I-negative\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n6 = piList[len(piList)-1][j]*estimate_transition(\"I-positive\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    n7 = piList[len(piList)-1][j]*estimate_transition(\"I-neutral\", previous_tag)*estimate_emission_fix(dev_in_list[i],previous_tag)\n",
    "                    #find the max, put this into a dict/list\n",
    "                    nList.append(n1)\n",
    "                    nList.append(n2)\n",
    "                    nList.append(n3)\n",
    "                    nList.append(n4)\n",
    "                    nList.append(n5)\n",
    "                    nList.append(n6)\n",
    "                    nList.append(n7)\n",
    "                    maxN = max(nList)\n",
    "                    print('MAX towards next node of tag ' + previous_tag)\n",
    "                    print(maxN)\n",
    "                    #append the max into piLayer2 and append piLayer2 into piList\n",
    "                    piLayer.append(maxN)\n",
    "                 \n",
    "                print('LAYER HERE')\n",
    "                print(piLayer)\n",
    "                piList.append(piLayer)\n",
    "            \n",
    "            if dev_in_list[i]==\"\":\n",
    "                beginning= True\n",
    "        print(piList)\n",
    "              \n",
    "                \n",
    "viterbi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
